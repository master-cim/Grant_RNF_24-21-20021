{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf15c54",
   "metadata": {},
   "source": [
    "## Искусственный интеллект в диагностике неисправностей и оценке состояния электросетевого оборудования\n",
    "Рег. № НИОКТР 124062800006-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8803ec3",
   "metadata": {},
   "source": [
    "Ниже представлен пример кода для Google Colab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd262bd7",
   "metadata": {},
   "source": [
    "## GraphSAGE\n",
    " Демонстрирвция применения направленного графа  к задаче обнаружения дефектов в электрооборудовании на основе графовой структуры, извлечённой из базы данных Neo4j. В этом примере используется библиотека StellarGraph для построения и обучения модели, а также интеграция с Neo4j для извлечения подграфов и характеристик узлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6b0b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек StellarGraph, если они ещё не установлены\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    %pip install -q stellargraph[demo]==1.3.0b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c452791",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import stellargraph as sg\n",
    "from stellargraph.connector.neo4j import Neo4jDirectedGraphSAGENodeGenerator, Neo4jStellarDiGraph\n",
    "from stellargraph.layer import DirectedGraphSAGE\n",
    "from tensorflow.keras import layers, optimizers, losses, Model\n",
    "from sklearn import preprocessing, model_selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import py2neo\n",
    "import os\n",
    "\n",
    "# Подключение к базе данных Neo4j\n",
    "neo4j_host = os.environ.get(\"NEO4J_HOST\", \"bolt://localhost:7687\")\n",
    "neo4j_graphdb = py2neo.Graph(host=neo4j_host, auth=(\"neo4j\", \"password\"))\n",
    "\n",
    "# Создание объекта графа из Neo4j, фильтруя узлы по метке \"Component\"\n",
    "neo4j_graph = Neo4jStellarDiGraph(neo4j_graphdb, node_label=\"Component\")\n",
    "neo4j_graph.cache_all_nodes_in_memory()\n",
    "\n",
    "# Извлечение меток дефектов для каждого компонента\n",
    "labels_query = \"\"\"\n",
    "MATCH (n:Component)\n",
    "RETURN n.id AS ID, n.defect_label AS label\n",
    "\"\"\"\n",
    "rows = neo4j_graphdb.run(labels_query).data()\n",
    "labels_series = pd.Series(\n",
    "    [row[\"label\"] for row in rows], index=[row[\"ID\"] for row in rows]\n",
    ")\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "train_labels, test_labels = model_selection.train_test_split(\n",
    "    labels_series, train_size=0.1, stratify=labels_series\n",
    ")\n",
    "\n",
    "# Кодирование меток в бинарный формат\n",
    "target_binarizer = preprocessing.LabelBinarizer()\n",
    "train_targets = target_binarizer.fit_transform(train_labels)\n",
    "test_targets = target_binarizer.transform(test_labels)\n",
    "\n",
    "# Создание генератора данных для обучения\n",
    "batch_size = 50\n",
    "in_samples = [5, 2]  # число соседей на входе\n",
    "out_samples = [5, 2] # число соседей на выходе\n",
    "\n",
    "generator = Neo4jDirectedGraphSAGENodeGenerator(\n",
    "    neo4j_graph, batch_size, in_samples, out_samples\n",
    ")\n",
    "\n",
    "train_gen = generator.flow(train_labels.index, train_targets, shuffle=True)\n",
    "test_gen = generator.flow(test_labels.index, test_targets)\n",
    "\n",
    "# Определение модели GraphSAGE\n",
    "layer_sizes = [32, 32]\n",
    "graphsage_model = DirectedGraphSAGE(\n",
    "    layer_sizes=layer_sizes, generator=generator, bias=True, dropout=0.5\n",
    ")\n",
    "\n",
    "# Получение входных и выходных тензоров модели\n",
    "x_inp, x_out = graphsage_model.in_out_tensors()\n",
    "\n",
    "# Добавление слоя классификации\n",
    "prediction = layers.Dense(units=train_targets.shape[1], activation=\"softmax\")(x_out)\n",
    "\n",
    "# Компиляция модели\n",
    "model = Model(inputs=x_inp, outputs=prediction)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.005),\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=20,\n",
    "    validation_data=test_gen,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Оценка модели на тестовых данных\n",
    "test_metrics = model.evaluate(test_gen)\n",
    "print(f\"\\nТочность на тестовом наборе: {test_metrics[1]:.4f}\")\n",
    "\n",
    "# Предсказания для всех компонентов\n",
    "all_nodes = labels_series.index\n",
    "all_mapper = generator.flow(all_nodes)\n",
    "predictions = model.predict(all_mapper)\n",
    "predicted_labels = target_binarizer.inverse_transform(predictions)\n",
    "\n",
    "# Визуализация результатов\n",
    "results_df = pd.DataFrame({\n",
    "    \"Predicted\": predicted_labels,\n",
    "    \"Actual\": labels_series.loc[all_nodes]\n",
    "})\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9116b8e9",
   "metadata": {},
   "source": [
    " ## EvoGraphNet \n",
    " — методика, сочетающая эволюционные алгоритмы и графовые нейросети, для автоматической оптимизации модели обнаружения дефектов в электрооборудовании. Структура графа, отражающая взаимосвязи компонентов, извлекается из базы данных Neo4j, что позволяет учитывать сложные направленные связи и особенности системы.\n",
    "\n",
    "Данный подход обеспечивает автоматический подбор архитектуры модели, что особенно важно при работе с динамическими и сложными графами, где ручная настройка параметров затруднена."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14812d54",
   "metadata": {},
   "source": [
    "Краткое описание\n",
    "*  Устанавливаем необходимые библиотеки, включая evo-graphnet, которая содержит реализацию эволюционного поиска архитектур.\n",
    "*  Подключаемся к Neo4j, извлекаем графовые данные и метки дефектов.\n",
    "* Разделяем данные для обучения и тестирования.\n",
    "*  Используем EvoGraphNet для автоматической эволюционной оптимизации модели.\n",
    "*  Обучаем модель и делаем предсказания, выводя результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882abb10",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    %pip install -q stellargraph[demo]==1.3.0b neo4j evo-graphnet\n",
    "\n",
    "# Импорт необходимых модулей\n",
    "import stellargraph as sg\n",
    "from stellargraph.connector.neo4j import Neo4jStellarDiGraph\n",
    "from evo_graphnet import EvoGraphNet\n",
    "import pandas as pd\n",
    "import py2neo\n",
    "import os\n",
    "\n",
    "# Подключение к базе данных Neo4j\n",
    "neo4j_host = os.environ.get(\"NEO4J_HOST\", \"bolt://localhost:7687\")\n",
    "neo4j_auth = (\"neo4j\", \"password\")  # замените на ваши данные\n",
    "neo4j_db = py2neo.Graph(host=neo4j_host, auth=neo4j_auth)\n",
    "\n",
    "# Извлечение графа из Neo4j\n",
    "neo4j_graph = Neo4jStellarDiGraph(neo4j_db, node_label=\"Component\")\n",
    "neo4j_graph.cache_all_nodes_in_memory()\n",
    "\n",
    "# Загрузка меток дефектов для компонентов\n",
    "labels_query = \"\"\"\n",
    "MATCH (n:Component)\n",
    "RETURN n.id AS ID, n.defect_label AS label\n",
    "\"\"\"\n",
    "rows = neo4j_db.run(labels_query).data()\n",
    "labels_series = pd.Series(\n",
    "    [row[\"label\"] for row in rows], index=[row[\"ID\"] for row in rows]\n",
    ")\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "from sklearn import model_selection, preprocessing\n",
    "train_labels, test_labels = model_selection.train_test_split(\n",
    "    labels_series, train_size=0.1, stratify=labels_series\n",
    ")\n",
    "\n",
    "# Бинаризация меток\n",
    "target_binarizer = preprocessing.LabelBinarizer()\n",
    "train_targets = target_binarizer.fit_transform(train_labels)\n",
    "test_targets = target_binarizer.transform(test_labels)\n",
    "\n",
    "# Инициализация EvoGraphNet для автоматической настройки модели\n",
    "evog = EvoGraphNet(\n",
    "    graph=neo4j_graph,\n",
    "    node_label=\"Component\",\n",
    "    target=train_labels.values,\n",
    "    population_size=20,\n",
    "    generations=10,\n",
    "    mutation_rate=0.2,\n",
    "    crossover_rate=0.8,\n",
    "    max_depth=3,\n",
    "    output_dim=len(target_binarizer.classes_),\n",
    "    # параметры эволюции и модели\n",
    ")\n",
    "\n",
    "# Обучение модели с помощью EvoGraphNet\n",
    "evog.fit(\n",
    "    epochs=50,\n",
    "    train_idx=train_labels.index,\n",
    "    validation_idx=test_labels.index,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Получение лучшей найденной модели\n",
    "best_model = evog.get_best_model()\n",
    "\n",
    "# Оценка модели\n",
    "test_predictions = best_model.predict(test_labels.index)\n",
    "predicted_labels = target_binarizer.inverse_transform(test_predictions)\n",
    "\n",
    "# Визуализация результатов\n",
    "results_df = pd.DataFrame({\n",
    "    \"Predicted\": predicted_labels,\n",
    "    \"Actual\": labels_series.loc[test_labels.index]\n",
    "})\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9092a",
   "metadata": {},
   "source": [
    "## Объединённый пример: автоматическая настройка EvoGraphNet + анализ с направленным GraphSAGE\n",
    "Этот объединённый пример показывает, как:\n",
    "\n",
    "* Автоматически оптимизировать модель обнаружения дефектов в электрооборудовании при помощи EvoGraphNet, извлекая данные из Neo4j.\n",
    "* Использовать направленный GraphSAGE для анализа структурированных направленных связей компонентов, моделируя причинно-следственные взаимодействия и улучшая диагностику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ea927",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    %pip install -q stellargraph[demo]==1.3.0b neo4j evo-graphnet\n",
    "\n",
    "# Импорт библиотек\n",
    "import stellargraph as sg\n",
    "from stellargraph.connector.neo4j import Neo4jDirectedGraphSAGENodeGenerator, Neo4jStellarDiGraph\n",
    "from evo_graphnet import EvoGraphNet\n",
    "from stellargraph.layer import DirectedGraphSAGE\n",
    "from tensorflow.keras import layers, optimizers, losses, Model\n",
    "from sklearn import preprocessing, model_selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import py2neo\n",
    "import os\n",
    "\n",
    "# Подключение к Neo4j\n",
    "neo4j_host = os.environ.get(\"NEO4J_HOST\", \"bolt://localhost:7687\")\n",
    "neo4j_auth = (\"neo4j\", \"password\")  # Замените на ваши данные\n",
    "neo4j_db = py2neo.Graph(host=neo4j_host, auth=neo4j_auth)\n",
    "\n",
    "# Создаем граф из Neo4j\n",
    "neo4j_graph = Neo4jStellarDiGraph(neo4j_db, node_label=\"Component\")\n",
    "neo4j_graph.cache_all_nodes_in_memory()\n",
    "\n",
    "# Извлечение меток дефектов\n",
    "labels_query = \"\"\"\n",
    "MATCH (n:Component)\n",
    "RETURN n.id AS ID, n.defect_label AS label\n",
    "\"\"\"\n",
    "rows = neo4j_db.run(labels_query).data()\n",
    "labels_series = pd.Series(\n",
    "    [row[\"label\"] for row in rows], index=[row[\"ID\"] for row in rows]\n",
    ")\n",
    "\n",
    "# Разделение данных\n",
    "train_labels, test_labels = model_selection.train_test_split(\n",
    "    labels_series, train_size=0.1, stratify=labels_series\n",
    ")\n",
    "\n",
    "# Кодирование меток\n",
    "target_binarizer = preprocessing.LabelBinarizer()\n",
    "train_targets = target_binarizer.fit_transform(train_labels)\n",
    "test_targets = target_binarizer.transform(test_labels)\n",
    "\n",
    "# --- Эволюционный автоматический подбор модели EvoGraphNet ---\n",
    "\n",
    "evog = EvoGraphNet(\n",
    "    graph=neo4j_graph,\n",
    "    node_label=\"Component\",\n",
    "    target=train_labels.values,\n",
    "    population_size=20,\n",
    "    generations=10,\n",
    "    mutation_rate=0.2,\n",
    "    crossover_rate=0.8,\n",
    "    max_depth=3,\n",
    "    output_dim=len(target_binarizer.classes_),\n",
    ")\n",
    "\n",
    "# Обучение с автоматической настройкой архитектуры\n",
    "evog.fit(\n",
    "    epochs=50,\n",
    "    train_idx=train_labels.index,\n",
    "    validation_idx=test_labels.index,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = evog.get_best_model()\n",
    "\n",
    "# Предсказания на тестовых данных\n",
    "test_predictions = best_model.predict(test_labels.index)\n",
    "predicted_labels = target_binarizer.inverse_transform(test_predictions)\n",
    "\n",
    "# Результаты\n",
    "results_df = pd.DataFrame({\n",
    "    \"Predicted\": predicted_labels,\n",
    "    \"Actual\": labels_series.loc[test_labels.index]\n",
    "})\n",
    "print(\"Результаты EvoGraphNet:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# --- Анализ направленного графа с помощью GraphSAGE ---\n",
    "\n",
    "# Создаем генератор данных для направленного графа\n",
    "batch_size = 50\n",
    "in_samples = [5, 2]\n",
    "out_samples = [5, 2]\n",
    "\n",
    "generator = Neo4jDirectedGraphSAGENodeGenerator(\n",
    "    neo4j_graph, batch_size, in_samples, out_samples\n",
    ")\n",
    "\n",
    "# Обучающий и тестовый генератор\n",
    "train_gen = generator.flow(train_labels.index, train_targets, shuffle=True)\n",
    "test_gen = generator.flow(test_labels.index, test_targets)\n",
    "\n",
    "# Определение модели GraphSAGE\n",
    "layer_sizes = [32, 32]\n",
    "graphsage_model = DirectedGraphSAGE(\n",
    "    layer_sizes=layer_sizes, generator=generator, bias=True, dropout=0.5\n",
    ")\n",
    "\n",
    "# Получение входных и выходных тензоров\n",
    "x_inp, x_out = graphsage_model.in_out_tensors()\n",
    "\n",
    "# Добавление слоя классификации\n",
    "prediction = layers.Dense(units=train_targets.shape[1], activation=\"softmax\")(x_out)\n",
    "\n",
    "# Компиляция модели\n",
    "model = Model(inputs=x_inp, outputs=prediction)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.005),\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Обучение модели GraphSAGE\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=20,\n",
    "    validation_data=test_gen,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Оценка модели\n",
    "test_metrics = model.evaluate(test_gen)\n",
    "print(f\"\\nТочность GraphSAGE на тестовых данных: {test_metrics[1]:.4f}\")\n",
    "\n",
    "# Предсказания для всех узлов\n",
    "all_nodes = labels_series.index\n",
    "all_mapper = generator.flow(all_nodes)\n",
    "predictions = model.predict(all_mapper)\n",
    "predicted_labels = target_binarizer.inverse_transform(predictions)\n",
    "\n",
    "# Визуализация результатов\n",
    "results_df_sage = pd.DataFrame({\n",
    "    \"Predicted\": predicted_labels,\n",
    "    \"Actual\": labels_series.loc[all_nodes]\n",
    "})\n",
    "print(\"Результаты GraphSAGE:\")\n",
    "print(results_df_sage.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbba2ff",
   "metadata": {},
   "source": [
    "Ниже представлен пример кода, который демонстрирует, как использовать EvoGraphNet для автоматической настройки модели прогнозирования связи между узлами на основе их параметров, а также как применить направленный GraphSAGE для извлечения признаков и предсказания связи, извлекая данные из Neo4j.\n",
    "Краткие пояснения:\n",
    "* Извлечение данных из Neo4j: получаем параметры узлов и существующие связи.\n",
    "* Формирование обучающей выборки: создаем все возможные пары узлов, отмечая существующие связи как 1, а отсутствующие — как 0.\n",
    "* Граф: создаем объект StellarGraph с узлами и их признаками.\n",
    "* Генератор: использует Neo4jDirectedGraphSAGENodeGenerator для подготовки батчей.\n",
    "* Модель: строится с помощью DirectedGraphSAGE, а финальный слой — сигмоид для бинарной классификации.\n",
    "* Обучение и предсказание: модель обучается и делает прогнозы вероятности существования связи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd7ba3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    %pip install -q stellargraph evo-graphnet neo4j\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import py2neo\n",
    "import os\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.connector.neo4j import Neo4jDirectedGraphSAGENodeGenerator\n",
    "from evo_graphnet import EvoGraphNet\n",
    "from stellargraph.layer import DirectedGraphSAGE\n",
    "from tensorflow.keras import layers, optimizers, losses, Model\n",
    "from sklearn import preprocessing, model_selection\n",
    "\n",
    "# Настройка соединения с Neo4j\n",
    "neo4j_host = os.environ.get(\"NEO4J_HOST\", \"bolt://localhost:7687\")\n",
    "neo4j_auth = (\"neo4j\", \"password\")  # замените на свои данные\n",
    "neo4j_db = py2neo.Graph(host=neo4j_host, auth=neo4j_auth)\n",
    "\n",
    "# Извлечение узлов и параметров\n",
    "nodes_query = \"\"\"\n",
    "MATCH (n:Component)\n",
    "RETURN n.id AS id, n.param1 AS param1, n.param2 AS param2, n.param3 AS param3\n",
    "\"\"\"\n",
    "nodes_df = pd.DataFrame(neo4j_db.run(nodes_query).data())\n",
    "nodes_df.set_index('id', inplace=True)\n",
    "\n",
    "# Предположим, что у нас есть информация о связях между узлами\n",
    "edges_query = \"\"\"\n",
    "MATCH (a:Component)-[r:CONNECTED_TO]->(b:Component)\n",
    "RETURN a.id AS source, b.id AS target\n",
    "\"\"\"\n",
    "edges_df = pd.DataFrame(neo4j_db.run(edges_query).data())\n",
    "\n",
    "# Создаем граф StellarGraph\n",
    "graph = StellarGraph(nodes=nodes_df)\n",
    "\n",
    "# Для задачи предсказания связи создадим целевую переменную\n",
    "# Для этого необходимо отметить существующие связи как 1, а отсутствующие - как 0\n",
    "# В простом случае можно взять все возможные пары и отметить существующие связи\n",
    "all_pairs = pd.merge(\n",
    "    nodes_df.reset_index(), nodes_df.reset_index(),\n",
    "    how='cross', suffixes=('_source', '_target')\n",
    ")\n",
    "# Фильтруем пары, которые есть в графе\n",
    "existing_edges = set(zip(edges_df['source'], edges_df['target']))\n",
    "all_pairs['has_edge'] = all_pairs.apply(\n",
    "    lambda row: 1 if (row['id_source'], row['id_target']) in existing_edges else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# В качестве признаков для узлов используем их параметры\n",
    "node_features = nodes_df.values\n",
    "target_labels = all_pairs['has_edge'].values\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "train_idx, test_idx = model_selection.train_test_split(\n",
    "    np.arange(len(all_pairs)),\n",
    "    train_size=0.8,\n",
    "    stratify=target_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Создаем генератор для обучения\n",
    "batch_size = 50\n",
    "in_samples = [10, 5]  # число соседей на входе\n",
    "out_samples = [10, 5]\n",
    "\n",
    "generator = Neo4jDirectedGraphSAGENodeGenerator(\n",
    "    graph, batch_size, in_samples, out_samples\n",
    ")\n",
    "\n",
    "# Генераторы для обучения и тестирования\n",
    "train_gen = generator.flow(\n",
    "    all_pairs.iloc[train_idx]['id_source'].values,\n",
    "    all_pairs.iloc[train_idx]['id_target'].values,\n",
    "    targets=target_labels[train_idx]\n",
    ")\n",
    "\n",
    "test_gen = generator.flow(\n",
    "    all_pairs.iloc[test_idx]['id_source'].values,\n",
    "    all_pairs.iloc[test_idx]['id_target'].values,\n",
    "    targets=target_labels[test_idx]\n",
    ")\n",
    "\n",
    "# Определение модели GraphSAGE\n",
    "layer_sizes = [32, 32]\n",
    "graphsage = DirectedGraphSAGE(\n",
    "    layer_sizes=layer_sizes,\n",
    "    generator=generator,\n",
    "    bias=True,\n",
    "    dropout=0.5\n",
    ")\n",
    "x_inp, x_out = graphsage.in_out_tensors()\n",
    "\n",
    "# Слой классификации\n",
    "prediction = layers.Dense(units=1, activation='sigmoid')(x_out)\n",
    "\n",
    "# Компиляция модели\n",
    "model = Model(inputs=x_inp, outputs=prediction)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.005),\n",
    "    loss=losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=20,\n",
    "    validation_data=test_gen,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Предсказания о существовании связи\n",
    "preds = model.predict(test_gen)\n",
    "# Можно интерпретировать preds как вероятность наличия связи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e84f4f5",
   "metadata": {},
   "source": [
    "Ниже представлен пример кода для Google Colab, реализующий описанный подход — обучение графовой нейронной сети (GNN) на одном репрезентативном образце, использования априорного шаблона признаков, а также применение модели для прогнозирования и классификации состояния электрооборудования. В качестве основы используется библиотека StellarGraph, а также возможна интеграция с PyTorch или TensorFlow для реализации GAT и других компонентов.\n",
    "Ключевые моменты:\n",
    "* Извлечение данных из Neo4j — получение графа и признаков.\n",
    "* Создание априорного шаблона C — усреднение или подбор образцов.\n",
    "* Обучение GAT — с помощью StellarGraph, на одном репрезентативном образце.\n",
    "* Прогнозирование состояния/связи — с помощью предсказаний модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df253bcf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "!pip install stellargraph tensorflow py2neo numpy pandas scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.layer import GraphAttention\n",
    "from stellargraph.mapper import GraphNodeGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from py2neo import Graph\n",
    "\n",
    "# Установка соединения с Neo4j\n",
    "neo4j_host = \"bolt://localhost:7687\"  # укажите свой хост\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_password = \"password\"  # замените на свой пароль\n",
    "\n",
    "graph_db = Graph(neo4j_host, auth=(neo4j_user, neo4j_password))\n",
    "\n",
    "# 1. Извлечение данных\n",
    "# Получение узлов и их признаков\n",
    "query_nodes = \"\"\"\n",
    "MATCH (n:Equipment)\n",
    "RETURN n.id AS id, n.param1 AS param1, n.param2 AS param2, n.param3 AS param3\n",
    "\"\"\"\n",
    "nodes_data = pd.DataFrame(graph_db.run(query_nodes).data())\n",
    "nodes_data.set_index('id', inplace=True)\n",
    "\n",
    "# Получение связей (например, связи между компонентами)\n",
    "query_edges = \"\"\"\n",
    "MATCH (a:Equipment)-[:CONNECTED_TO]->(b:Equipment)\n",
    "RETURN a.id AS source, b.id AS target\n",
    "\"\"\"\n",
    "edges_data = pd.DataFrame(graph_db.run(query_edges).data())\n",
    "\n",
    "# 2. Создаем граф StellarGraph\n",
    "# В качестве признаков используем параметры узлов\n",
    "feature_columns = ['param1', 'param2', 'param3']\n",
    "node_features = nodes_data[feature_columns].values\n",
    "nodes_df = nodes_data.copy()\n",
    "\n",
    "# Создаем граф\n",
    "G = StellarGraph(nodes=nodes_df, edges=edges_data)\n",
    "\n",
    "# 3. Формируем шаблон признаков (априорный шаблон C)\n",
    "# Предположим, что у нас есть образцы признаков для каждого класса\n",
    "# Для демонстрации возьмем случайные образцы или подготовим вручную\n",
    "sample_patterns = [\n",
    "    np.array([[0.5, 0.2, 0.1], [0.4, 0.3, 0.2]]),  # пример 1\n",
    "    np.array([[0.6, 0.1, 0.3], [0.5, 0.2, 0.4]]),  # пример 2\n",
    "    # добавьте свои шаблоны\n",
    "]\n",
    "# Минимизируем расстояние Фробениуса до этих образцов для получения шаблона C\n",
    "C = np.mean(sample_patterns, axis=0)  # аппроксимация\n",
    "\n",
    "# 4. Обучение модели GNN на одном образце (пример)\n",
    "# Для этого создадим простую модель GAT с помощью StellarGraph\n",
    "\n",
    "# Создаем генератор\n",
    "generator = GraphNodeGenerator(G, batch_size=16, method=\"gat\")\n",
    "\n",
    "train_gen = generator.flow(nodes_df.index)\n",
    "\n",
    "# Определяем модель GAT\n",
    "gat_layer = GraphAttention(layer_sizes=[8, 8], attn_heads=8, generator=generator, dropout=0.5)\n",
    "x_inp, x_out = gat_layer.in_out_tensors()\n",
    "\n",
    "# Добавляем выходной слой для задачи классификации (например, бинарной)\n",
    "output = tf.keras.layers.Dense(units=1, activation='sigmoid')(x_out)\n",
    "\n",
    "model = tf.keras.Model(inputs=x_inp, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Предположим, у нас есть метки для узлов (например, дефект/норма)\n",
    "# Для демонстрации создадим случайные метки\n",
    "labels = np.random.randint(0, 2, size=len(nodes_df))\n",
    "labels = pd.Series(labels, index=nodes_df.index)\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(train_gen, epochs=10, validation_data=train_gen)  # замените на validation при наличии\n",
    "\n",
    "# 5. Прогнозирование и классификация\n",
    "predictions = model.predict(train_gen)\n",
    "print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3ff71",
   "metadata": {},
   "source": [
    "Пример, как можно использовать априорный шаблон C в качестве регуляризации или дополнительного вспомогательного сигнала при обучении графовой нейронной сети. \n",
    "Идея — добавить к функции потерь число, которое поощряет сходство представлений узлов модели с шаблоном C, например, через норму Фробениуса.\n",
    "* Пусть у вас есть векторные представления узлов модели — X_pred.\n",
    "* У вас есть априорный шаблон C.\n",
    "* Можно минимизировать расстояние между X_pred и C, как дополнительную составляющую функции потерь, чтобы модель училась учитывать априорную информацию.\n",
    "\n",
    "Варианты использования априорного шаблона C\n",
    "* В качестве регулятора — поощрять сходство представлений с шаблоном для повышения стабильности.\n",
    "* В качестве вспомогательного сигнала — добавлять его в функцию потерь для усиления нужных характеристик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12604f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Допустим, у нас есть:\n",
    "# x_out — выходные признаки узлов модели (например, из GAT)\n",
    "# C — априорный шаблон признаков (например, матрица r×r)\n",
    "\n",
    "# Встроим регуляризацию в функцию потерь\n",
    "def custom_loss(y_true, y_pred, X_pred, C, lambda_reg=0.1):\n",
    "    # Основная потеря (например, бинарная кросс-энтропия)\n",
    "    base_loss = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "    # Расстояние Фробениуса между представлениями и шаблоном\n",
    "    frobenius_norm = tf.norm(X_pred - C, ord='fro', axis=[-2, -1])  # по матрицам признаков\n",
    "    reg_loss = tf.reduce_mean(frobenius_norm)\n",
    "    return base_loss + lambda_reg * reg_loss\n",
    "\n",
    "# В случае обучения модели в Keras\n",
    "# Предположим, что у вас есть:\n",
    "# - x_inp: входные тензоры\n",
    "# - x_out: выходные признаки (например, из слоя GAT)\n",
    "# - y_true: истинные метки\n",
    "\n",
    "# Тогда можно определить свою функцию потерь, передавая C и X_pred\n",
    "\n",
    "# Например, при обучении так:\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_gen:\n",
    "        X_batch, y_batch = batch\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Предсказания\n",
    "            y_pred_batch = model(X_batch)\n",
    "            # Получение представлений узлов (например, из промежуточных слоев)\n",
    "            X_pred = ...  # зависит от архитектуры, например, извлечь из модели\n",
    "            # Расчет потерь\n",
    "            loss_value = custom_loss(y_batch, y_pred_batch, X_pred, C, lambda_reg=0.1)\n",
    "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493be14f",
   "metadata": {},
   "source": [
    "Пример, который показывает, как интегрировать априорный шаблон C в обучение модели GAT, используя TensorFlow и StellarGraph. \n",
    "Ключевые моменты::\n",
    "*  Создаем отдельную модель feature_extractor, чтобы извлечь представления узлов после слоя GAT.\n",
    "* Расстояние между представлениями и шаблоном C_template добавляется в функцию потерь как регуляризация. В данном примере C_template — случайный, но на практике это ваш априорный шаблон признаков, который можно подобрать или вычислить статически.\n",
    "* Обучение происходит через стандартный цикл с автоматическим расчетом градиентов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809125b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.layer import GraphAttention\n",
    "from stellargraph.mapper import GraphNodeGenerator\n",
    "\n",
    "# Предположим, что у вас есть граф G и узлы с признаками\n",
    "# (Используем тот же граф, что и в предыдущем примере)\n",
    "# Для демонстрации создадим фиктивные данные\n",
    "\n",
    "# Создадим фиктивный граф\n",
    "nodes = pd.DataFrame({\n",
    "    \"feature1\": np.random.rand(10),\n",
    "    \"feature2\": np.random.rand(10),\n",
    "    \"feature3\": np.random.rand(10),\n",
    "}, index=[f\"node_{i}\" for i in range(10)])\n",
    "\n",
    "edges = pd.DataFrame({\n",
    "    \"source\": [\"node_0\", \"node_1\", \"node_2\", \"node_3\"],\n",
    "    \"target\": [\"node_1\", \"node_2\", \"node_3\", \"node_4\"]\n",
    "})\n",
    "\n",
    "G = StellarGraph(nodes=nodes, edges=edges)\n",
    "\n",
    "# Создаем генератор\n",
    "generator = GraphNodeGenerator(G, batch_size=2, method=\"gat\")\n",
    "train_gen = generator.flow(nodes.index)\n",
    "\n",
    "# Определяем модель GAT\n",
    "gat_layer = GraphAttention(layer_sizes=[8], attn_heads=4, generator=generator, dropout=0.0)\n",
    "x_inp, x_out = gat_layer.in_out_tensors()\n",
    "\n",
    "# В выходе у нас есть признаки узлов после GAT\n",
    "# Предположим, что задача — бинарная классификация (например, дефект или норма)\n",
    "output = tf.keras.layers.Dense(units=1, activation='sigmoid')(x_out)\n",
    "model = tf.keras.Model(inputs=x_inp, outputs=output)\n",
    "\n",
    "# Компиляция без регуляризации (будем добавлять вручную)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Создаем фиктивные метки\n",
    "labels = np.random.randint(0, 2, size=(len(nodes), 1))\n",
    "labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "# Предположим, что у нас есть априорный шаблон C (например, для класса 0 и 1)\n",
    "# Для простоты возьмем случайный шаблон\n",
    "C_template = np.random.rand(8, 1)  # размерность совпадает с выходом слоя GAT\n",
    "\n",
    "# Обучение с регуляризацией\n",
    "epochs = 20\n",
    "lambda_reg = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for batch in train_gen:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Получаем предсказания\n",
    "            pred = model(batch[0], training=True)  # batch[0] — входные данные\n",
    "            # В модели x_out — это выход GAT слоя\n",
    "            # Но так как мы используем keras модель, нужно извлечь его\n",
    "            # Для этого сделаем отдельную модель для получения представлений\n",
    "            # или получим их из промежуточного слоя\n",
    "            # Для простоты — создадим модель для представлений\n",
    "            feature_extractor = tf.keras.Model(inputs=x_inp, outputs=x_out)\n",
    "            node_embeddings = feature_extractor(batch[0])  # получаем представления узлов\n",
    "\n",
    "            # Расчет регуляризации: расстояние Фробениуса между представлениями и шаблоном C\n",
    "            # Можно сделать по всем узлам\n",
    "            # Используем tf.norm по последним двум осям\n",
    "            frobenius_dist = tf.norm(node_embeddings - C_template.T, axis=[-2, -1])  # shape: (batch_size, num_nodes)\n",
    "            reg_loss = tf.reduce_mean(frobenius_dist)\n",
    "\n",
    "            # Основная потеря\n",
    "            bce_loss = tf.keras.losses.BinaryCrossentropy()(labels[batch[1]], pred)\n",
    "\n",
    "            # Итоговая потеря\n",
    "            total_loss = bce_loss + lambda_reg * reg_loss\n",
    "\n",
    "        # Градиенты и обновление\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    print(f\"Loss: {total_loss.numpy():.4f}\")\n",
    "\n",
    "# После обучения можно использовать модель для предсказаний\n",
    "preds = model.predict(next(iter(train_gen)))\n",
    "print(\"Predictions:\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7a042",
   "metadata": {},
   "source": [
    "### Автоматическая подгонка шаблона C\n",
    "Обучение модели без регуляризации: сначала обучить модель без регуляризации шаблона.\n",
    "Расчет шаблона C: после этого — для каждого класса вычислить средний вектор признаков узлов, полученных на обучающей выборке, и использовать эти средние как шаблоны.\n",
    "Использование шаблонов: далее — при обучении добавлять регуляризацию, которая поощряет представления узлов к этим шаблонам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b14fa",
   "metadata": {},
   "source": [
    "#### Шаг 1: Обучение без регуляризации и сбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb2d17",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Обучение модели без регуляризации шаблона\n",
    "# и сбор признаков узлов для каждого класса\n",
    "\n",
    "# Создаем модель для извлечения признаков\n",
    "feature_extractor = tf.keras.Model(inputs=x_inp, outputs=x_out)\n",
    "\n",
    "# Инициализируем списки для хранения признаков по классам\n",
    "class_features = {0: [], 1: []}\n",
    "\n",
    "# Проходим по всему датасету\n",
    "for batch in train_gen:\n",
    "    # Получаем входные данные\n",
    "    inputs = batch[0]\n",
    "    # Получаем метки\n",
    "    labels_batch = labels[batch[1]]\n",
    "    # Извлекаем признаки узлов\n",
    "    features = feature_extractor(inputs)\n",
    "    # Собираем признаки по классам\n",
    "    for i in range(features.shape[0]):\n",
    "        label_cls = int(labels_batch[i].numpy())\n",
    "        class_features[label_cls].append(features[i].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae3c67c",
   "metadata": {},
   "source": [
    "#### Шаг 2: Вычисление шаблонов (средних признаков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a77b174",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Вычисляем средние признаки для каждого класса\n",
    "C_templates = {}\n",
    "for cls in class_features:\n",
    "    C_templates[cls] = np.mean(class_features[cls], axis=0)  # shape: (feature_dim,)\n",
    "# Преобразуем в массивы для использования\n",
    "C_templates_array = {\n",
    "    cls: tf.convert_to_tensor(c, dtype=tf.float32)\n",
    "    for cls, c in C_templates.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ab48a",
   "metadata": {},
   "source": [
    " #### Шаг 3: Обучение с регуляризацией по полученным шаблонам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0b4cc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Далее, при обучении, используем эти шаблоны\n",
    "# Например, для каждого узла, соответствующего класса, можем подстроить регуляризацию\n",
    "# В данном случае — сделаем так, чтобы узлы с метками класса 0 приближались к C_templates[0], и аналогично для класса 1\n",
    "\n",
    "# Обучение с регуляризацией\n",
    "epochs = 20\n",
    "lambda_reg = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_gen:\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = model(batch[0], training=True)\n",
    "            labels_batch = labels[batch[1]]\n",
    "            # Извлекаем признаки узлов\n",
    "            node_embeddings = feature_extractor(batch[0])\n",
    "\n",
    "            # Для каждого узла, по его метке, берем соответствующий шаблон\n",
    "            reg_losses = []\n",
    "            for i in range(node_embeddings.shape[0]):\n",
    "                label_cls = int(labels_batch[i].numpy())\n",
    "                c_template = C_templates_array[label_cls]\n",
    "                dist = tf.norm(node_embeddings[i] - c_template)\n",
    "                reg_losses.append(dist)\n",
    "\n",
    "            reg_loss = tf.reduce_mean(reg_losses)\n",
    "            bce_loss = tf.keras.losses.BinaryCrossentropy()(labels_batch, pred)\n",
    "            total_loss = bce_loss + lambda_reg * reg_loss\n",
    "\n",
    "        # Обновление модели\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37db1f1",
   "metadata": {},
   "source": [
    "## Обучение модели для предсказания динамики графов (EvoGraphNet)\n",
    "Моделируется развитие графа как последовательность признаков.\n",
    "Обучается рекуррентная модель предсказывать признаки следующего шага.\n",
    "В дальнейшем можно строить генеративные модели для более точного моделирования и генерации новых графов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cb15bd",
   "metadata": {},
   "source": [
    "#### 1. Генерация данных (симуляция)\n",
    "Для примера создадим последовательность графов, которые развиваются со временем, например, добавляя или удаляя рёбра/узлы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7dfa0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def generate_graph_sequence(n_nodes=10, t_steps=5):\n",
    "    \"\"\"\n",
    "    Генерирует последовательность графов, где на каждом шаге добавляются/удаляются рёбра.\n",
    "    \"\"\"\n",
    "    graphs = []\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(n_nodes))\n",
    "    for t in range(t_steps):\n",
    "        # На каждом шаге случайно добавляем/удаляем рёбра\n",
    "        if t > 0:\n",
    "            # Время для обновления рёбер\n",
    "            for _ in range(np.random.randint(1, 4)):\n",
    "                u, v = np.random.choice(n_nodes, 2, replace=False)\n",
    "                if G.has_edge(u, v):\n",
    "                    G.remove_edge(u, v)\n",
    "                else:\n",
    "                    G.add_edge(u, v)\n",
    "        graphs.append(G.copy())\n",
    "    return graphs\n",
    "\n",
    "sequence = generate_graph_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39929c3",
   "metadata": {},
   "source": [
    "#### 2. Преобразование графов в признаки\n",
    "Для обучения модели нужно представить графы в виде матриц признаков или эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb62d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def graph_to_features(G):\n",
    "    \"\"\"\n",
    "    Преобразует граф G в матрицу признаков узлов (например, степень, центральность и т.п.)\n",
    "    \"\"\"\n",
    "    degrees = np.array([G.degree(n) for n in G.nodes()])\n",
    "    # Можно добавить другие признаки\n",
    "    features = degrees.reshape(-1, 1)\n",
    "    return features\n",
    "\n",
    "# Создаем последовательности признаков\n",
    "features_sequence = [graph_to_features(G) for G in sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82c18d",
   "metadata": {},
   "source": [
    "#### 3. Построение модели предсказания\n",
    "Модель принимает признаки текущего графа и предсказывает признаки следующего.\n",
    "\n",
    "Можно реализовать, например, простую рекуррентную нейронную сеть (RNN) или графовую нейросеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df5b38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Предположим, что признаки узлов имеют размерность d\n",
    "d = features_sequence[0].shape[1]\n",
    "\n",
    "# Создаем модель\n",
    "model_input = layers.Input(shape=(None, d))  # последовательность признаков\n",
    "x = layers.LSTM(32, return_sequences=True)(model_input)\n",
    "x = layers.TimeDistributed(layers.Dense(d))(x)\n",
    "model = tf.keras.Model(inputs=model_input, outputs=x)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b0c836",
   "metadata": {},
   "source": [
    "#### 4. Обучение модели\n",
    "Подготовим данные: последовательности признаков для каждого временного интервала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf133b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Создаем обучающую выборку: вход — т. n, целевое — т. n+1\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for t in range(len(features_sequence) - 1):\n",
    "    X_train.append(features_sequence[t])\n",
    "    Y_train.append(features_sequence[t+1])\n",
    "\n",
    "# Преобразуем в массивы\n",
    "X_train = tf.ragged.constant(X_train).to_tensor()\n",
    "Y_train = tf.ragged.constant(Y_train).to_tensor()\n",
    "\n",
    "# Обучение\n",
    "model.fit(X_train, Y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd4ac3",
   "metadata": {},
   "source": [
    "#### 5. Предсказание развития системы\n",
    "После обучения можно предсказать развитие графа, подавая на вход признаки текущего графа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ce055",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Текущий граф\n",
    "current_features = features_sequence[-1][np.newaxis, ...]  # добавляем размер батча\n",
    "predicted_features = model.predict(current_features)\n",
    "\n",
    "# На основе предсказанных признаков можно реконструировать граф\n",
    "# Например, по признакам степени строить рёбра\n",
    "predicted_degrees = predicted_features[0, :, 0]\n",
    "threshold = np.median(predicted_degrees)\n",
    "predicted_edges = []\n",
    "for i, deg in enumerate(predicted_degrees):\n",
    "    if deg > threshold:\n",
    "        for j in range(i+1, len(predicted_degrees)):\n",
    "            if predicted_degrees[j] > threshold:\n",
    "                predicted_edges.append((i, j))\n",
    "# Построим предсказанный граф\n",
    "G_pred = nx.Graph()\n",
    "G_pred.add_nodes_from(range(len(predicted_degrees)))\n",
    "G_pred.add_edges_from(predicted_edges)\n",
    "nx.draw(G_pred, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8666d",
   "metadata": {},
   "source": [
    "## Оценка индекса здоровья оборудования (ИЗО) и прогнозирования остаточного ресурса.\n",
    " В коде:\n",
    "* Генерирует случайные данные признаков узлов за несколько временных точек.\n",
    "* Вычисляет разницу состояния узлов относительно окружения.\n",
    "* Формирует признаки для связей между узлами.\n",
    "* Обучает простую нейросеть предсказания ухудшения связей.\n",
    "* Вычисляет потенциалы и веса связей.\n",
    "* На основе этих данных рассчитывает индекс здоровья и остаточный ресурс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a38dea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Установка параметров\n",
    "np.random.seed(42)\n",
    "num_nodes = 10  # Количество узлов\n",
    "num_features = 5  # Количество признаков каждого узла\n",
    "timesteps = 3   # Количество временных точек\n",
    "R_max = 100  # Максимальный ресурс оборудования\n",
    "beta = 0.5   # Коэффициент масштабирования для весов\n",
    "\n",
    "# 1. Генерируем исходные данные: признаки узлов на разные временные точки\n",
    "# Для простоты создадим случайные данные\n",
    "h_s_t = np.random.rand(timesteps, num_nodes, num_features)  # Текущие состояния\n",
    "h_g_L = np.mean(h_s_t, axis=0)  # Средние признаки по окружению для каждого узла\n",
    "\n",
    "# 2. Вычисляем изменение состояния каждого узла относительно окружения\n",
    "delta_h = h_s_t[-1] - np.mean(h_g_L, axis=0)  # Для последнего времени\n",
    "\n",
    "# 3. Формируем признаки X_(i,j) для связей между узлами\n",
    "X_ij_list = []\n",
    "pairs = []\n",
    "for i in range(num_nodes):\n",
    "    for j in range(i+1, num_nodes):\n",
    "        # Объединяем признаки узлов i и j и разницу\n",
    "        feature_i = h_g_L[i]\n",
    "        feature_j = h_g_L[j]\n",
    "        delta_i = delta_h[i]\n",
    "        delta_j = delta_h[j]\n",
    "        # Для модели предсказания ухудшения связи\n",
    "        X_ij = np.concatenate([feature_i, feature_j, [delta_i], [delta_j]])\n",
    "        X_ij_list.append(X_ij)\n",
    "        pairs.append((i, j))\n",
    "\n",
    "X_ij_array = np.array(X_ij_list)\n",
    "\n",
    "# 4. Создаем модель для предсказания ухудшения связи y_hat_(i,j)\n",
    "input_dim = X_ij_array.shape[1]\n",
    "model_input = layers.Input(shape=(input_dim,))\n",
    "x = layers.Dense(8, activation='relu')(model_input)\n",
    "x = layers.Dense(4, activation='relu')(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = models.Model(inputs=model_input, outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# 5. Для обучения создадим искусственные метки (например, случайные или на основе логики)\n",
    "# Здесь для примера зададим случайные метки\n",
    "labels = np.random.randint(0, 2, size=(len(X_ij_array), 1))\n",
    "\n",
    "# 6. Обучение модели\n",
    "model.fit(X_ij_array, labels, epochs=50, verbose=0)\n",
    "\n",
    "# 7. Вычисляем веса W и смещение b для каждой связи\n",
    "W_weights = model.layers[-2].get_weights()[0]  # Веса последнего слоя перед выходом\n",
    "b_weights = model.layers[-1].get_weights()[0]  # Смещение\n",
    "\n",
    "# 8. Расчет вероятностей ухудшения для каждой связи\n",
    "preds = model.predict(X_ij_array).flatten()\n",
    "\n",
    "# 9. Расчет потенциалов f_i(x_i) для каждого узла\n",
    "# Для этого можно усреднить вероятности ухудшения связей, связанных с узлом i\n",
    "w_i = np.zeros(num_nodes)\n",
    "connection_counts = np.zeros(num_nodes)\n",
    "\n",
    "for idx, (i, j) in enumerate(pairs):\n",
    "    w_i[i] += preds[idx]\n",
    "    w_i[j] += preds[idx]\n",
    "    connection_counts[i] += 1\n",
    "    connection_counts[j] += 1\n",
    "\n",
    "# 10. Нормализация потенциалов и вычисление весов w_i по формуле (21) и (22)\n",
    "f_i = w_i / (connection_counts + 1e-8)  # чтобы избежать деления на ноль\n",
    "max_f_i = np.max(f_i)\n",
    "w_normalized = beta * (f_i / (max_f_i + 1e-8))\n",
    "w_normalized = np.clip(w_normalized, 0, 1)  # диапазон [0,1]\n",
    "\n",
    "# 11. Расчет Индекса здоровья (ИЗО) по формуле (23)\n",
    "# В предположении, что link(P_si, D_si) — это вероятность ухудшения\n",
    "# Итоговая сумма по связям\n",
    "sum_links = 0\n",
    "sum_weights = 0\n",
    "\n",
    "for idx, (i, j) in enumerate(pairs):\n",
    "    sum_links += w_normalized[i] * preds[idx]\n",
    "    sum_links += w_normalized[j] * preds[idx]\n",
    "    sum_weights += w_normalized[i]\n",
    "    sum_weights += w_normalized[j]\n",
    "\n",
    "IZO = 100 * (1 - (sum_links / (sum_weights + 1e-8)))\n",
    "\n",
    "# 12. Расчет остаточного ресурса\n",
    "R_o = R_max * IZO / 100\n",
    "\n",
    "# Выводим результаты\n",
    "print(f\"Индекс здоровья оборудования (ИЗО): {IZO:.2f}%\")\n",
    "print(f\"Остаточный ресурс: {R_o:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd75ef",
   "metadata": {},
   "source": [
    "## Оценка риска отказа оборудования и планирования техобслуживания с помощью генетического алгоритма. \n",
    "В этом коде:\n",
    "\n",
    "* Генерирует вероятности отказа узлов и связанные параметры.\n",
    "* Определяет риск отказа и сроки обслуживания.\n",
    "* Использует генетический алгоритм для поиска оптимальных дат обслуживания, минимизирующих функцию стоимости J.\n",
    "* В качестве функции стоимости — сумма риска отказа и времени обслуживания с весами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526a9a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Параметры\n",
    "num_nodes = 10  # Количество узлов\n",
    "num_objects = 3  # Количество оборудования\n",
    "np.random.seed(42)\n",
    "\n",
    "# Вероятности отказа узлов p_x (по формуле (26))\n",
    "p_x = np.random.uniform(0.01, 0.2, size=num_nodes)\n",
    "\n",
    "# Связь узлов с оборудованием N_(O_j) (пример данных)\n",
    "N_Oj = {\n",
    "    0: [0, 1, 2, 3],\n",
    "    1: [4, 5, 6],\n",
    "    2: [7, 8, 9]\n",
    "}\n",
    "\n",
    "# Время обслуживания узлов T_x (пример данных)\n",
    "T_x = np.random.uniform(1, 5, size=num_nodes)\n",
    "\n",
    "# Весовые коэффициенты w_x (отражают важность узлов) (нормализуем)\n",
    "w_x = np.random.uniform(0.1, 0.5, size=num_nodes)\n",
    "w_x /= np.sum(w_x)  # сумма равна 1\n",
    "\n",
    "# Влияние отказа узлов на риск отказа оборудования по формуле (25)\n",
    "def risk_of_object(N_Oj, p_x):\n",
    "    R_Oj = {}\n",
    "    for j, nodes in N_Oj.items():\n",
    "        prod = 1.0\n",
    "        for x in nodes:\n",
    "            prod *= (1 - p_x[x])\n",
    "        R_Oj[j] = 1 - prod  # по формуле (25)\n",
    "    return R_Oj\n",
    "\n",
    "# Общий риск отказа оборудования (сумма или максимум, по выбору)\n",
    "risk_Oj = risk_of_object(N_Oj, p_x)\n",
    "\n",
    "# Время обслуживания оборудования – по формуле (27) или (28)\n",
    "def compute_T_Oj(N_Oj, T_x, weights=None):\n",
    "    T_Oj = {}\n",
    "    for j, nodes in N_Oj.items():\n",
    "        if weights is None:\n",
    "            T_Oj[j] = np.max([T_x[x] for x in nodes])  # максимум по формуле (27)\n",
    "        else:\n",
    "            T_Oj[j] = np.sum([w_x[x] * T_x[x] for x in nodes])  # взвешенно по формуле (28)\n",
    "    return T_Oj\n",
    "\n",
    "T_Oj_max = compute_T_Oj(N_Oj, T_x)\n",
    "T_Oj_weighted = compute_T_Oj(N_Oj, T_x, weights=w_x)\n",
    "\n",
    "# Приоритетные веса узлов w_x уже вычислены (нормализованы)\n",
    "\n",
    "# Расчет функции стоимости J по формуле (29)\n",
    "alpha = 1.0  # вес риска\n",
    "beta = 0.5   # вес времени обслуживания\n",
    "\n",
    "# Для каждого объекта вычисляем J\n",
    "J_Oj_max = {}\n",
    "J_Oj_weighted = {}\n",
    "for j in range(num_objects):\n",
    "    risk_j = risk_of_object({j: N_Oj[j]}, p_x)[j]\n",
    "    T_max = T_Oj_max[j]\n",
    "    T_weighted = T_Oj_weighted[j]\n",
    "    J_max = alpha * risk_j + beta * T_max  # по формуле (29)\n",
    "    J_weighted = alpha * risk_j + beta * T_weighted  # по формуле (29)\n",
    "    J_Oj_max[j] = J_max\n",
    "    J_Oj_weighted[j] = J_weighted\n",
    "\n",
    "# Общая стоимость по объектам (по сумме)\n",
    "J_total_max = sum(J_Oj_max.values())\n",
    "J_total_weighted = sum(J_Oj_weighted.values())\n",
    "\n",
    "print(f\"Общая стоимость (максимальный срок): {J_total_max:.3f}\")\n",
    "print(f\"Общая стоимость (взвешенный срок): {J_total_weighted:.3f}\")\n",
    "\n",
    "# Расчет риска отказа всей системы (по формуле (25))\n",
    "# Предположим, что оборудование связано, и риск отказа:\n",
    "def risk_system(N_Oj, p_x):\n",
    "    prod = 1.0\n",
    "    for j in N_Oj:\n",
    "        risk_j = risk_of_object({j: N_Oj[j]}, p_x)[j]\n",
    "        prod *= (1 - risk_j)\n",
    "    return 1 - prod\n",
    "\n",
    "risk_system_value = risk_system(N_Oj, p_x)\n",
    "print(f\"Риск отказа системы: {risk_system_value:.3f}\")\n",
    "\n",
    "# Расчет общего риска отказа оборудования по формуле (30)\n",
    "J_system_max = alpha * risk_system_value + beta * max(T_Oj_max.values())\n",
    "J_system_weighted = alpha * risk_system_value + beta * sum(w_x[x] * T_x[x] for x in range(num_nodes))\n",
    "\n",
    "print(f\"Итоговая стоимость системы (максимальные сроки): {J_system_max:.3f}\")\n",
    "print(f\"Итоговая стоимость системы (взвешенные сроки): {J_system_weighted:.3f}\")\n",
    "\n",
    "# Расчет срока выполнения обслуживания для системы\n",
    "# Максимальное или взвешенное\n",
    "T_service_max = max(T_Oj_max.values())\n",
    "T_service_weighted = sum(w_x[x] * T_x[x] for x in range(num_nodes))\n",
    "\n",
    "print(f\"Общий срок обслуживания (максимум): {T_service_max:.3f}\")\n",
    "print(f\"Общий срок обслуживания (взвешенно): {T_service_weighted:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
