{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Подготовка и выявление проблем исходного набора данных**"
      ],
      "metadata": {
        "id": "sLr_7HQpxx28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перед реализацией алгоритмов машинного обучения была проводится процедура инжиниринга данных."
      ],
      "metadata": {
        "id": "VzV1rDSO1DGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gdown\n",
        "url = 'https://drive.google.com/uc?id=1nytZOYptCgRVEfxH1qX53sS_XAG9MFv6'  # Замените FILE_ID на идентификатор вашего файла\n",
        "output = 'dataset.csv'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "collapsed": true,
        "id": "mQ8z81m3yCj_",
        "outputId": "a8d147a2-74b6-4ae5-e760-e33c05a83edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nytZOYptCgRVEfxH1qX53sS_XAG9MFv6\n",
            "To: /content/dataset.csv\n",
            "100%|██████████| 5.96k/5.96k [00:00<00:00, 11.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = pd.read_csv(output)\n",
        "ds.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "collapsed": true,
        "id": "VO3qx1bx0gZe",
        "outputId": "2a578744-c8bc-4b4e-db49-a0d2cd7b82e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  №\\№   pd1   pd2   pd3  opt1  opt2  opt3  opt4  opt5  opt6  ...  res16  \\\n",
              "0  Т1  1.10  7.52  0.97  1280  1480  1360  0.74  0.71  0.71  ...      0   \n",
              "1  Т2  0.57  3.74  0.91  2050   707  1230  0.99  0.89  0.94  ...      0   \n",
              "2  Т3  1.10  7.52  0.16  1350  1150  1210  1.71  1.70  1.73  ...      0   \n",
              "3  Т4  0.80  5.33  1.13   368   530   390  1.78  1.72  1.74  ...      0   \n",
              "4  Т5  0.80  5.33  1.69   101   125    14  1.55  1.41  1.46  ...      0   \n",
              "\n",
              "   res17  res18  res19  res20  res21  res22  res23  res24  res25  \n",
              "0      0      0      0      1      1      1      1      1      1  \n",
              "1      0      0      0      1      1      0      1      1      1  \n",
              "2      0      0      0      1      1      0      1      1      1  \n",
              "3      0      0      0      0      1      0      1      1      1  \n",
              "4      0      0      0      0      1      0      1      1      1  \n",
              "\n",
              "[5 rows x 56 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a86e253-873d-420a-8e80-b91a82c6960d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>№\\№</th>\n",
              "      <th>pd1</th>\n",
              "      <th>pd2</th>\n",
              "      <th>pd3</th>\n",
              "      <th>opt1</th>\n",
              "      <th>opt2</th>\n",
              "      <th>opt3</th>\n",
              "      <th>opt4</th>\n",
              "      <th>opt5</th>\n",
              "      <th>opt6</th>\n",
              "      <th>...</th>\n",
              "      <th>res16</th>\n",
              "      <th>res17</th>\n",
              "      <th>res18</th>\n",
              "      <th>res19</th>\n",
              "      <th>res20</th>\n",
              "      <th>res21</th>\n",
              "      <th>res22</th>\n",
              "      <th>res23</th>\n",
              "      <th>res24</th>\n",
              "      <th>res25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Т1</td>\n",
              "      <td>1.10</td>\n",
              "      <td>7.52</td>\n",
              "      <td>0.97</td>\n",
              "      <td>1280</td>\n",
              "      <td>1480</td>\n",
              "      <td>1360</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.71</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Т2</td>\n",
              "      <td>0.57</td>\n",
              "      <td>3.74</td>\n",
              "      <td>0.91</td>\n",
              "      <td>2050</td>\n",
              "      <td>707</td>\n",
              "      <td>1230</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Т3</td>\n",
              "      <td>1.10</td>\n",
              "      <td>7.52</td>\n",
              "      <td>0.16</td>\n",
              "      <td>1350</td>\n",
              "      <td>1150</td>\n",
              "      <td>1210</td>\n",
              "      <td>1.71</td>\n",
              "      <td>1.70</td>\n",
              "      <td>1.73</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Т4</td>\n",
              "      <td>0.80</td>\n",
              "      <td>5.33</td>\n",
              "      <td>1.13</td>\n",
              "      <td>368</td>\n",
              "      <td>530</td>\n",
              "      <td>390</td>\n",
              "      <td>1.78</td>\n",
              "      <td>1.72</td>\n",
              "      <td>1.74</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Т5</td>\n",
              "      <td>0.80</td>\n",
              "      <td>5.33</td>\n",
              "      <td>1.69</td>\n",
              "      <td>101</td>\n",
              "      <td>125</td>\n",
              "      <td>14</td>\n",
              "      <td>1.55</td>\n",
              "      <td>1.41</td>\n",
              "      <td>1.46</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 56 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a86e253-873d-420a-8e80-b91a82c6960d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a86e253-873d-420a-8e80-b91a82c6960d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a86e253-873d-420a-8e80-b91a82c6960d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-20cd6676-3e71-4b2d-886b-41f9d1976381\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20cd6676-3e71-4b2d-886b-41f9d1976381')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-20cd6676-3e71-4b2d-886b-41f9d1976381 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ds"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.iloc[1:, 1:]\n",
        "ds.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ijsEmCe4yFNX",
        "outputId": "f375b4c2-f160-4c05-c59c-bdbac1c7bee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25 entries, 1 to 25\n",
            "Data columns (total 55 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   pd1     25 non-null     float64\n",
            " 1   pd2     25 non-null     float64\n",
            " 2   pd3     25 non-null     float64\n",
            " 3   opt1    25 non-null     int64  \n",
            " 4   opt2    25 non-null     int64  \n",
            " 5   opt3    25 non-null     int64  \n",
            " 6   opt4    25 non-null     float64\n",
            " 7   opt5    25 non-null     float64\n",
            " 8   opt6    25 non-null     float64\n",
            " 9   opt7    25 non-null     float64\n",
            " 10  opt8    25 non-null     float64\n",
            " 11  opt9    25 non-null     float64\n",
            " 12  opt10   25 non-null     float64\n",
            " 13  opt11   25 non-null     float64\n",
            " 14  opt12   25 non-null     float64\n",
            " 15  opt13   25 non-null     float64\n",
            " 16  opt14   25 non-null     float64\n",
            " 17  opt15   25 non-null     float64\n",
            " 18  opt16   25 non-null     float64\n",
            " 19  opt17   25 non-null     float64\n",
            " 20  opt18   25 non-null     float64\n",
            " 21  opt19   25 non-null     float64\n",
            " 22  opt20   25 non-null     float64\n",
            " 23  opt21   25 non-null     float64\n",
            " 24  opt22   25 non-null     float64\n",
            " 25  opt23   25 non-null     float64\n",
            " 26  opt24   25 non-null     float64\n",
            " 27  opt25   25 non-null     float64\n",
            " 28  opt26   25 non-null     float64\n",
            " 29  opt27   25 non-null     float64\n",
            " 30  res1    25 non-null     int64  \n",
            " 31  res2    25 non-null     int64  \n",
            " 32  res3    25 non-null     int64  \n",
            " 33  res4    25 non-null     int64  \n",
            " 34  res5    25 non-null     int64  \n",
            " 35  res6    25 non-null     int64  \n",
            " 36  res7    25 non-null     int64  \n",
            " 37  res8    25 non-null     int64  \n",
            " 38  res9    25 non-null     int64  \n",
            " 39  res10   25 non-null     int64  \n",
            " 40  res11   25 non-null     int64  \n",
            " 41  res12   25 non-null     int64  \n",
            " 42  res13   25 non-null     int64  \n",
            " 43  res14   25 non-null     int64  \n",
            " 44  res15   25 non-null     int64  \n",
            " 45  res16   25 non-null     int64  \n",
            " 46  res17   25 non-null     int64  \n",
            " 47  res18   25 non-null     int64  \n",
            " 48  res19   25 non-null     int64  \n",
            " 49  res20   25 non-null     int64  \n",
            " 50  res21   25 non-null     int64  \n",
            " 51  res22   25 non-null     int64  \n",
            " 52  res23   25 non-null     int64  \n",
            " 53  res24   25 non-null     int64  \n",
            " 54  res25   25 non-null     int64  \n",
            "dtypes: float64(27), int64(28)\n",
            "memory usage: 10.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "collapsed": true,
        "id": "sMzOQFti0lxi",
        "outputId": "2153aa0b-3862-41b5-99aa-f13506fa8c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             pd1        pd2        pd3         opt1         opt2         opt3  \\\n",
              "count  25.000000  25.000000  25.000000    25.000000    25.000000    25.000000   \n",
              "mean    0.716400   4.774000   1.040000  1611.960000  1248.160000  1301.560000   \n",
              "std     0.200018   1.420337   0.511468  2028.496703  1409.214488  1176.375014   \n",
              "min     0.300000   1.870000   0.160000    29.000000    83.000000    14.000000   \n",
              "25%     0.570000   3.740000   0.600000   291.000000   323.000000   390.000000   \n",
              "50%     0.790000   5.320000   1.030000   735.000000   853.000000  1210.000000   \n",
              "75%     0.800000   5.330000   1.500000  1912.000000  1465.000000  1558.000000   \n",
              "max     1.100000   7.520000   1.930000  8390.000000  6500.000000  4600.000000   \n",
              "\n",
              "            opt4       opt5       opt6       opt7  ...  res16  res17  res18  \\\n",
              "count  25.000000  25.000000  25.000000  25.000000  ...   25.0   25.0   25.0   \n",
              "mean    1.432400   1.022000   1.025600   1.010000  ...    0.0    0.0    0.0   \n",
              "std     1.612716   0.283387   0.292006   0.979847  ...    0.0    0.0    0.0   \n",
              "min     0.550000   0.470000   0.500000   0.020000  ...    0.0    0.0    0.0   \n",
              "25%     0.900000   0.880000   0.840000   0.360000  ...    0.0    0.0    0.0   \n",
              "50%     1.150000   0.980000   0.970000   0.610000  ...    0.0    0.0    0.0   \n",
              "75%     1.320000   1.140000   1.110000   1.210000  ...    0.0    0.0    0.0   \n",
              "max     9.040000   1.720000   1.740000   3.680000  ...    0.0    0.0    0.0   \n",
              "\n",
              "       res19      res20  res21  res22      res23  res24  res25  \n",
              "count   25.0  25.000000   25.0   25.0  25.000000  25.00  25.00  \n",
              "mean     0.0   0.440000    1.0    0.0   0.640000   0.96   0.96  \n",
              "std      0.0   0.506623    0.0    0.0   0.489898   0.20   0.20  \n",
              "min      0.0   0.000000    1.0    0.0   0.000000   0.00   0.00  \n",
              "25%      0.0   0.000000    1.0    0.0   0.000000   1.00   1.00  \n",
              "50%      0.0   0.000000    1.0    0.0   1.000000   1.00   1.00  \n",
              "75%      0.0   1.000000    1.0    0.0   1.000000   1.00   1.00  \n",
              "max      0.0   1.000000    1.0    0.0   1.000000   1.00   1.00  \n",
              "\n",
              "[8 rows x 55 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2940a508-ff91-4215-bdfa-052c68eb1bbf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pd1</th>\n",
              "      <th>pd2</th>\n",
              "      <th>pd3</th>\n",
              "      <th>opt1</th>\n",
              "      <th>opt2</th>\n",
              "      <th>opt3</th>\n",
              "      <th>opt4</th>\n",
              "      <th>opt5</th>\n",
              "      <th>opt6</th>\n",
              "      <th>opt7</th>\n",
              "      <th>...</th>\n",
              "      <th>res16</th>\n",
              "      <th>res17</th>\n",
              "      <th>res18</th>\n",
              "      <th>res19</th>\n",
              "      <th>res20</th>\n",
              "      <th>res21</th>\n",
              "      <th>res22</th>\n",
              "      <th>res23</th>\n",
              "      <th>res24</th>\n",
              "      <th>res25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.00</td>\n",
              "      <td>25.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.716400</td>\n",
              "      <td>4.774000</td>\n",
              "      <td>1.040000</td>\n",
              "      <td>1611.960000</td>\n",
              "      <td>1248.160000</td>\n",
              "      <td>1301.560000</td>\n",
              "      <td>1.432400</td>\n",
              "      <td>1.022000</td>\n",
              "      <td>1.025600</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.200018</td>\n",
              "      <td>1.420337</td>\n",
              "      <td>0.511468</td>\n",
              "      <td>2028.496703</td>\n",
              "      <td>1409.214488</td>\n",
              "      <td>1176.375014</td>\n",
              "      <td>1.612716</td>\n",
              "      <td>0.283387</td>\n",
              "      <td>0.292006</td>\n",
              "      <td>0.979847</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.506623</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.489898</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.870000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.570000</td>\n",
              "      <td>3.740000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>323.000000</td>\n",
              "      <td>390.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.790000</td>\n",
              "      <td>5.320000</td>\n",
              "      <td>1.030000</td>\n",
              "      <td>735.000000</td>\n",
              "      <td>853.000000</td>\n",
              "      <td>1210.000000</td>\n",
              "      <td>1.150000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.800000</td>\n",
              "      <td>5.330000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1912.000000</td>\n",
              "      <td>1465.000000</td>\n",
              "      <td>1558.000000</td>\n",
              "      <td>1.320000</td>\n",
              "      <td>1.140000</td>\n",
              "      <td>1.110000</td>\n",
              "      <td>1.210000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.100000</td>\n",
              "      <td>7.520000</td>\n",
              "      <td>1.930000</td>\n",
              "      <td>8390.000000</td>\n",
              "      <td>6500.000000</td>\n",
              "      <td>4600.000000</td>\n",
              "      <td>9.040000</td>\n",
              "      <td>1.720000</td>\n",
              "      <td>1.740000</td>\n",
              "      <td>3.680000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 55 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2940a508-ff91-4215-bdfa-052c68eb1bbf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2940a508-ff91-4215-bdfa-052c68eb1bbf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2940a508-ff91-4215-bdfa-052c68eb1bbf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4dba56f4-d26d-4d47-ad54-31bb0e357229\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4dba56f4-d26d-4d47-ad54-31bb0e357229')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4dba56f4-d26d-4d47-ad54-31bb0e357229 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проанализировав исходный набор данных, был сделан вывод, о необходимости проведения серии исследовательских экспериментов, связанных с подготовкой исходного набора данных, обучением и оценкой моделей.\n",
        "Общая гипотеза экспериментов заключается в том, что от выбора обучающих и целевых признаков будет изменяться качество обучения моделей машинного обучения. При этом важно учитывать, что под качеством подразумевается не только достижение наилучших значений метрик оценки качества обучения, но и то, как конкретно влияют выбранные обучающие признаки на целевую для данной работы задачу классификации состояния изоляции силового масляного трансформатора.\n"
      ],
      "metadata": {
        "id": "t9K7njj61Ut3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подготовка к эксперименту №1**"
      ],
      "metadata": {
        "id": "JW7WTPYK8cqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цель эксперимента — проверить, могут ли модели машинного обучения эффективно прогнозировать состояние изоляции силового трансформатора, используя ограниченный набор данных (паспортные данные, визуальные осмотры, электротехнические измерения для 27 трансформаторов) без фильтрации признаков по их значимости. Эксперимент поможет подтвердить возможность применения ИИ в диагностике трансформаторов с минимальными исходными данными, определит подходящие алгоритмы и повысит надежность диагностики в условиях ограниченности данных. Ожидается, что некоторые модели смогут эффективно работать даже при минимальной предобработке, а результаты дадут рекомендации для дальнейшего применения ИИ в диагностике электрооборудования.\n",
        "\n",
        "В процессе подготовки решались проблемы низкого качества данных (пропуски и выбросы), дисбаланса классов и несоответствия масштабов признаков. Были применены методы предобработки: заполнение пропусков, удаление выбросов, настройка гиперпараметров для балансировки классов и масштабирование данных с помощью библиотек Python. Выводы указывают на необходимость увеличения данных, балансировки классов и использования подходящих метрик для повышения точности модели."
      ],
      "metadata": {
        "id": "-h7Srz018icD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подготовка к эксперименту №2**"
      ],
      "metadata": {
        "id": "znaHbWNL867Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цель эксперимента — выявить обучающие признаки из ограниченного набора данных, которые дадут наилучшие результаты в прогнозировании электрических характеристик силового масляного трансформатора. Ожидается, что удаление части признаков повлияет на качество обучения моделей, предоставив основы для оценки методов мониторинга и диагностики. Эксперимент покажет практическую применимость выбранных признаков и их влияние на избежание мультиколлинеарности.\n",
        "\n",
        "Для предотвращения шума и мультиколлинеарности были удалены такие признаки, как «Год изготовления», «Установленная мощность, кВА», «Пиковая мощность, кВА», «ПБН. Повреждение контактов», «ПБН. Отсутствие неповрежденных ответвлений», «Вводы. Повреждение уплотнений», «Радиаторы. Механическое повреждение», «Внешний осмотр воздухоосушителя. Отсутствие предусмотренного проектом воздухоосушителя», «Воздухоосушитель. Отсутствие», «Радиаторы. Отсутствие», и все признаки, связанные с внешним осмотром оборудования, так как они описывают внешние характеристики, не влияющие напрямую на прогнозирование электрических параметров."
      ],
      "metadata": {
        "id": "EhM0PRS09P2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Экспериментальная проверка базовых алгоритмов на ограниченном наборе входных данны**"
      ],
      "metadata": {
        "id": "NbUAeLPn9cEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Процесс разработки модели начинается с подготовки исходного набора данных, учитывая проблемы и особенности, описанные в подготовке для экспериментов №1 и №2. Далее данные загружаются в формате CSV, подготавливаются и делятся на обучающую и тестовую выборки (тренировочная — 20%). Затем данные масштабируются с помощью функций StandardScaler() и scaler.transform() из библиотеки sklearn.\n",
        "\n",
        "После преобразования данных модели обучаются с предварительной настройкой гиперпараметров. Корректируется дисбаланс классов и проводится их оптимизация с помощью алгоритма GridSearchCV, исследующего все комбинации гиперпараметров. Для оценки качества обучения применяются метрики: точность (accuracy), точность (precision), полнота (recall), F-мера (F1-score) и сводные метрики sklearn — Micro Average, Macro Average, Weighted Average и Samples Average. Weighted avg лучше подходит для задач с несбалансированными классами, учитывая их дисбаланс, а macro avg применяется, если классы сбалансированы, а samples avg используется для задач с многозначными метками."
      ],
      "metadata": {
        "id": "AdEnfg4M-QpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Процедурпа разработки моделей МО с применением различных алгоритмов**"
      ],
      "metadata": {
        "id": "9YFXcNZw-ZCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Алгоритм**: Логистическая регрессия\n"
      ],
      "metadata": {
        "id": "vZZXmYoNxIL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = ds.drop(ds.loc[:, 'res1':'res25'], axis=1)\n",
        "y = ds.loc[:, 'res1':'res25']\n",
        "\n",
        "# Разобъем наш DF на тестовую и обучающую выборку, используем ф-цию train_test_split()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "#Масштабирование данных\n",
        "numeric = ['pd1', 'pd2', 'pd3', 'opt1', 'opt2', 'opt3',\n",
        "       'opt4', 'opt5', 'opt6', 'opt7', 'opt8', 'opt9', 'opt10', 'opt11',\n",
        "       'opt12', 'opt13', 'opt14', 'opt15', 'opt16', 'opt17', 'opt18', 'opt19',\n",
        "       'opt20', 'opt21', 'opt22', 'opt23', 'opt24', 'opt25', 'opt26', 'opt27']\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_test[numeric])\n",
        "X_train[numeric] = scaler.transform(X_train[numeric])\n",
        "X_test[numeric] = scaler.transform(X_test[numeric])\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators=100, max_depth=7, class_weight='balanced')\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "random_forest.score(X_train, y_train)\n",
        "\n",
        "random_forest_train = round(random_forest.score(X_train, y_train) * 100, 2)\n",
        "random_forest_accuracy = round(accuracy_score(y_pred_rf, y_test) * 100, 2)\n",
        "\n",
        "print(\"Training Accuracy    :\",random_forest_train ,\"%\")\n",
        "print(\"Model Accuracy Score :\",random_forest_accuracy ,\"%\")\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n",
        "print(\"Classification_Report: \\n\",classification_report(y_test,y_pred_rf))\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg-zfrh-xaVD",
        "outputId": "e3507480-0030-441f-83bb-080d4aeab995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy    : 100.0 %\n",
            "Model Accuracy Score : 20.0 %\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n",
            "Classification_Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.50      1.00      0.67         2\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       1.00      1.00      1.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.60      1.00      0.75         3\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         3\n",
            "          20       1.00      1.00      1.00         5\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.75      0.75      0.75         4\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "   micro avg       0.88      0.90      0.89        48\n",
            "   macro avg       0.35      0.39      0.37        48\n",
            "weighted avg       0.85      0.90      0.87        48\n",
            " samples avg       0.88      0.90      0.89        48\n",
            "\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вариация с применением grid search (в результате Best Parameters : {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300})"
      ],
      "metadata": {
        "id": "MywMwgf4AASq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Разделение на признаки и целевые переменные\n",
        "X = ds.drop(ds.loc[:, 'res1':'res25'], axis=1)\n",
        "y = ds.loc[:, 'res1':'res25']\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# Масштабирование данных\n",
        "numeric = ['pd1', 'pd2', 'pd3', 'opt1', 'opt2', 'opt3',\n",
        "           'opt4', 'opt5', 'opt6', 'opt7', 'opt8', 'opt9', 'opt10', 'opt11',\n",
        "           'opt12', 'opt13', 'opt14', 'opt15', 'opt16', 'opt17', 'opt18', 'opt19',\n",
        "           'opt20', 'opt21', 'opt22', 'opt23', 'opt24', 'opt25', 'opt26', 'opt27']\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train[numeric])\n",
        "X_train[numeric] = scaler.transform(X_train[numeric])\n",
        "X_test[numeric] = scaler.transform(X_test[numeric])\n",
        "\n",
        "# Создание базовой модели RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(class_weight='balanced')\n",
        "\n",
        "# Задание сетки гиперпараметров для поиска\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Применение GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Лучшая модель и параметры\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Обучение лучшей модели на обучающих данных\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred_rf = best_model.predict(X_test)\n",
        "\n",
        "# Оценка модели\n",
        "random_forest_train = round(best_model.score(X_train, y_train) * 100, 2)\n",
        "random_forest_accuracy = round(accuracy_score(y_pred_rf, y_test) * 100, 2)\n",
        "\n",
        "print(\"Best Parameters      :\", best_params)\n",
        "print(\"Training Accuracy    :\", random_forest_train, \"%\")\n",
        "print(\"Model Accuracy Score :\", random_forest_accuracy, \"%\")\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_rf))\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EHlWpjLAAw7",
        "outputId": "d36b306f-4441-4a5e-feaa-950bc178878a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "324 fits failed out of a total of 972.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "324 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.04761905 0.04761905 0.04761905 0.         0.04761905 0.04761905\n",
            " 0.0952381  0.         0.         0.0952381  0.0952381  0.0952381\n",
            " 0.0952381  0.04761905 0.0952381  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0952381  0.         0.04761905 0.         0.04761905\n",
            " 0.04761905 0.04761905 0.04761905 0.04761905 0.         0.\n",
            " 0.0952381  0.0952381  0.0952381  0.04761905 0.0952381  0.0952381\n",
            " 0.         0.         0.                nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.0952381  0.04761905 0.         0.         0.04761905 0.04761905\n",
            " 0.04761905 0.04761905 0.04761905 0.04761905 0.         0.\n",
            " 0.0952381  0.0952381  0.04761905 0.0952381  0.0952381  0.0952381\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.04761905 0.04761905 0.         0.0952381  0.         0.\n",
            " 0.04761905 0.04761905 0.04761905 0.         0.04761905 0.04761905\n",
            " 0.         0.         0.         0.0952381  0.0952381  0.04761905\n",
            " 0.0952381  0.0952381  0.0952381  0.04761905 0.         0.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
            " 0.         0.         0.04761905 0.04761905 0.0952381  0.0952381\n",
            " 0.0952381  0.0952381  0.0952381  0.         0.         0.04761905\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.04761905 0.04761905 0.         0.04761905 0.04761905 0.04761905\n",
            " 0.04761905 0.04761905 0.04761905 0.         0.         0.\n",
            " 0.0952381  0.0952381  0.0952381  0.04761905 0.0952381  0.04761905\n",
            " 0.         0.         0.                nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.04761905 0.         0.         0.04761905 0.04761905 0.04761905\n",
            " 0.04761905 0.04761905 0.04761905 0.04761905 0.         0.\n",
            " 0.0952381  0.0952381  0.0952381  0.0952381  0.0952381  0.0952381\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.04761905 0.         0.\n",
            " 0.04761905 0.04761905 0.         0.         0.04761905 0.04761905\n",
            " 0.0952381  0.         0.         0.0952381  0.0952381  0.0952381\n",
            " 0.0952381  0.0952381  0.0952381  0.         0.04761905 0.        ]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters      : {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Training Accuracy    : 25.0 %\n",
            "Model Accuracy Score : 0.0 %\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       1.00      1.00      1.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.60      1.00      0.75         3\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.20      1.00      0.33         1\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         3\n",
            "          20       1.00      1.00      1.00         5\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.00      0.00      0.00         4\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "   micro avg       0.83      0.81      0.82        48\n",
            "   macro avg       0.31      0.36      0.32        48\n",
            "weighted avg       0.77      0.81      0.78        48\n",
            " samples avg       0.83      0.82      0.82        48\n",
            "\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Алгоритм**: Метод XGBoost"
      ],
      "metadata": {
        "id": "b08pqNO1Awfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = ds.drop(ds.loc[:, 'res1':'res25'], axis=1)\n",
        "y = ds.loc[:, 'res1':'res25']\n",
        "\n",
        "# Разобъем наш DF на тестовую и обучающую выборку, используем ф-цию train_test_split()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "#Масштабирование данных\n",
        "numeric = ['pd1', 'pd2', 'pd3', 'opt1', 'opt2', 'opt3',\n",
        "       'opt4', 'opt5', 'opt6', 'opt7', 'opt8', 'opt9', 'opt10', 'opt11',\n",
        "       'opt12', 'opt13', 'opt14', 'opt15', 'opt16', 'opt17', 'opt18', 'opt19',\n",
        "       'opt20', 'opt21', 'opt22', 'opt23', 'opt24', 'opt25', 'opt26', 'opt27']\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_test[numeric])\n",
        "X_train[numeric] = scaler.transform(X_train[numeric])\n",
        "X_test[numeric] = scaler.transform(X_test[numeric])\n",
        "\n",
        "\n",
        "xgb = xgb.XGBClassifier(random_state=12345, class_weight='balanced')\n",
        "xgb.fit(X_train,y_train)\n",
        "\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "xgb.score(X_train, y_train)\n",
        "\n",
        "\n",
        "xgb_train = round(xgb.score(X_train, y_train) * 100, 2)\n",
        "xgb_accuracy = round(accuracy_score(y_pred_xgb, y_test) * 100, 2)\n",
        "\n",
        "print(\"Training Accuracy    :\",xgb_train ,\"%\")\n",
        "print(\"Model Accuracy Score :\",xgb_accuracy ,\"%\")\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n",
        "print(\"Classification_Report: \\n\",classification_report(y_test,y_pred_xgb))\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sitwOYNQA1my",
        "outputId": "0f458d94-412b-499c-eb66-12f9125452e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:50:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"class_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy    : 85.0 %\n",
            "Model Accuracy Score : 0.0 %\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n",
            "Classification_Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.50      1.00      0.67         2\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       1.00      1.00      1.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.75      1.00      0.86         3\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         3\n",
            "          20       1.00      1.00      1.00         5\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.50      0.25      0.33         4\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "   micro avg       0.82      0.85      0.84        48\n",
            "   macro avg       0.35      0.37      0.35        48\n",
            "weighted avg       0.84      0.85      0.84        48\n",
            " samples avg       0.82      0.85      0.83        48\n",
            "\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "вариант с применением grid search"
      ],
      "metadata": {
        "id": "J_QP9SzjA49n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Разделение на признаки и целевые переменные\n",
        "X = ds.drop(ds.loc[:, 'res1':'res25'], axis=1)\n",
        "y = ds.loc[:, 'res1':'res25']\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "# Масштабирование данных\n",
        "numeric = ['pd1', 'pd2', 'pd3', 'opt1', 'opt2', 'opt3',\n",
        "           'opt4', 'opt5', 'opt6', 'opt7', 'opt8', 'opt9', 'opt10', 'opt11',\n",
        "           'opt12', 'opt13', 'opt14', 'opt15', 'opt16', 'opt17', 'opt18', 'opt19',\n",
        "           'opt20', 'opt21', 'opt22', 'opt23', 'opt24', 'opt25', 'opt26', 'opt27']\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train[numeric])\n",
        "X_train[numeric] = scaler.transform(X_train[numeric])\n",
        "X_test[numeric] = scaler.transform(X_test[numeric])\n",
        "\n",
        "# Создание базовой модели XGBClassifier\n",
        "xgb_model = xgb.XGBClassifier(random_state=12345)\n",
        "\n",
        "# Задание сетки гиперпараметров для поиска\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "    'scale_pos_weight': [1, 2, 3]  # Параметр для баланса классов\n",
        "}\n",
        "\n",
        "\n",
        "# Применение GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Лучшая модель и параметры\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Обучение лучшей модели на обучающих данных\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred_xgb = best_model.predict(X_test)\n",
        "\n",
        "# Оценка модели\n",
        "xgb_train = round(best_model.score(X_train, y_train) * 100, 2)\n",
        "xgb_accuracy = round(accuracy_score(y_pred_xgb, y_test) * 100, 2)\n",
        "\n",
        "print(\"Best Parameters      :\", best_params)\n",
        "print(\"Training Accuracy    :\", xgb_train, \"%\")\n",
        "print(\"Model Accuracy Score :\", xgb_accuracy, \"%\")\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_xgb))\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPVo8u9pA5-5",
        "outputId": "80f70209-ec4a-47a6-bfa1-ff883b953859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n",
            "Best Parameters      : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 2, 'subsample': 0.8}\n",
            "Training Accuracy    : 85.0 %\n",
            "Model Accuracy Score : 0.0 %\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.50      1.00      0.67         2\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       1.00      1.00      1.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.75      1.00      0.86         3\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         3\n",
            "          20       1.00      1.00      1.00         5\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.67      0.50      0.57         4\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "   micro avg       0.82      0.88      0.85        48\n",
            "   macro avg       0.36      0.38      0.36        48\n",
            "weighted avg       0.85      0.88      0.86        48\n",
            " samples avg       0.82      0.87      0.85        48\n",
            "\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель с подобранными идеальными параметрами (Best Parameters : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 2, 'subsample': 1.0})"
      ],
      "metadata": {
        "id": "N4mJvOYEBUoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Разделение на признаки и целевые переменные\n",
        "X = ds.drop(ds.loc[:, 'res1':'res25'], axis=1)\n",
        "y = ds.loc[:, 'res1':'res25']\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "# Масштабирование данных\n",
        "numeric = ['pd1', 'pd2', 'pd3', 'opt1', 'opt2', 'opt3',\n",
        "           'opt4', 'opt5', 'opt6', 'opt7', 'opt8', 'opt9', 'opt10', 'opt11',\n",
        "           'opt12', 'opt13', 'opt14', 'opt15', 'opt16', 'opt17', 'opt18', 'opt19',\n",
        "           'opt20', 'opt21', 'opt22', 'opt23', 'opt24', 'opt25', 'opt26', 'opt27']\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train[numeric])\n",
        "X_train[numeric] = scaler.transform(X_train[numeric])\n",
        "X_test[numeric] = scaler.transform(X_test[numeric])\n",
        "\n",
        "# Создание базовой модели XGBClassifier\n",
        "xgb_model = xgb.XGBClassifier(random_state=12345)\n",
        "\n",
        "# Задание сетки гиперпараметров для поиска\n",
        "param_grid = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [3],\n",
        "    'learning_rate': [0.1],\n",
        "    'subsample': [1.0],\n",
        "    'colsample_bytree': [0.8],\n",
        "    'scale_pos_weight': [2]  # Параметр для баланса классов\n",
        "}\n",
        "\n",
        "# Применение GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Лучшая модель и параметры\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Обучение лучшей модели на обучающих данных\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred_xgb = best_model.predict(X_test)\n",
        "\n",
        "# Оценка модели\n",
        "xgb_train = round(best_model.score(X_train, y_train) * 100, 2)\n",
        "xgb_accuracy = round(accuracy_score(y_pred_xgb, y_test) * 100, 2)\n",
        "\n",
        "print(\"Best Parameters      :\", best_params)\n",
        "print(\"Training Accuracy    :\", xgb_train, \"%\")\n",
        "print(\"Model Accuracy Score :\", xgb_accuracy, \"%\")\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_xgb))\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amRtpGbLBHVW",
        "outputId": "945acf35-ae74-4670-bb7c-d4679a97d40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best Parameters      : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 2, 'subsample': 1.0}\n",
            "Training Accuracy    : 85.0 %\n",
            "Model Accuracy Score : 0.0 %\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.33      0.50      0.40         2\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       1.00      1.00      1.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.75      1.00      0.86         3\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         3\n",
            "          20       1.00      1.00      1.00         5\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.67      0.50      0.57         4\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "   micro avg       0.82      0.85      0.84        48\n",
            "   macro avg       0.35      0.36      0.35        48\n",
            "weighted avg       0.85      0.85      0.85        48\n",
            " samples avg       0.82      0.85      0.83        48\n",
            "\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Алгоритм:** Метод опорных векторов (Support Vector Machines)"
      ],
      "metadata": {
        "id": "3YNXdsEKBcO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = ds.drop(ds.loc[:, 'res1':'res25'], axis=1)\n",
        "y_r = ds.loc[:, 'res1':'res25']\n",
        "\n",
        "y['faultType'] = ''\n",
        "for i in y_r.columns:\n",
        "  y['faultType'] += y_r[i].astype(str)\n",
        "\n",
        "y = y.drop(columns=y.columns.difference(['faultType']))\n",
        "\n",
        "# Разобъем наш DF на тестовую и обучающую выборку, используем ф-цию train_test_split()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "#Масштабирование данных\n",
        "numeric = ['pd1', 'pd2', 'pd3', 'opt1', 'opt2', 'opt3',\n",
        "       'opt4', 'opt5', 'opt6', 'opt7', 'opt8', 'opt9', 'opt10', 'opt11',\n",
        "       'opt12', 'opt13', 'opt14', 'opt15', 'opt16', 'opt17', 'opt18', 'opt19',\n",
        "       'opt20', 'opt21', 'opt22', 'opt23', 'opt24', 'opt25', 'opt26', 'opt27']\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_test[numeric])\n",
        "X_train[numeric] = scaler.transform(X_train[numeric])\n",
        "X_test[numeric] = scaler.transform(X_test[numeric])\n",
        "\n",
        "print('X_train', X_train.shape)\n",
        "print('X_test', X_test.shape)\n",
        "print('y_train', y_train.shape)\n",
        "print('y_test', y_test.shape)\n",
        "\n",
        "svc = SVC(random_state=12345, class_weight='balanced')\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "\n",
        "svc_train = round(svc.score(X_train, y_train) * 100, 2)\n",
        "svc_accuracy = round(accuracy_score(y_pred_svc, y_test) * 100, 2)\n",
        "\n",
        "print(\"Training Accuracy    :\",svc_train ,\"%\")\n",
        "print(\"Model Accuracy Score :\",svc_accuracy ,\"%\")\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n",
        "print(\"Classification_Report: \\n\",classification_report(y_test,y_pred_svc))\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfzG8Eh6BiA8",
        "outputId": "e819d860-3565-4538-e92f-5db446cbac0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (20, 30)\n",
            "X_test (5, 30)\n",
            "y_train (20, 1)\n",
            "y_test (5, 1)\n",
            "Training Accuracy    : 60.0 %\n",
            "Model Accuracy Score : 0.0 %\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n",
            "Classification_Report: \n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "1000110000000100000110111       0.00      0.00      0.00       1.0\n",
            "1000110000010100000110011       0.00      0.00      0.00       1.0\n",
            "1000110001000100000010111       0.00      0.00      0.00       1.0\n",
            "1000110001010100000010011       0.00      0.00      0.00       0.0\n",
            "1000110001110100000010011       0.00      0.00      0.00       0.0\n",
            "1100110001000100000010111       0.00      0.00      0.00       1.0\n",
            "1100110001000100000110111       0.00      0.00      0.00       1.0\n",
            "\n",
            "                 accuracy                           0.00       5.0\n",
            "                macro avg       0.00      0.00      0.00       5.0\n",
            "             weighted avg       0.00      0.00      0.00       5.0\n",
            "\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поиск лучших параметров с помощью grid search и обучение модели с их помощью\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "rEqF8jghB1xA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Разделение на признаки и целевые переменные\n",
        "X = ds.drop(ds.loc[:, 'res1':'res25'], axis=1)\n",
        "y_r = ds.loc[:, 'res1':'res25']\n",
        "\n",
        "# Создание целевой переменной 'faultType'\n",
        "y = pd.DataFrame()\n",
        "y['faultType'] = y_r.astype(str).agg(''.join, axis=1)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# Масштабирование данных\n",
        "numeric = ['pd1', 'pd2', 'pd3', 'opt1', 'opt2', 'opt3',\n",
        "           'opt4', 'opt5', 'opt6', 'opt7', 'opt8', 'opt9', 'opt10', 'opt11',\n",
        "           'opt12', 'opt13', 'opt14', 'opt15', 'opt16', 'opt17', 'opt18', 'opt19',\n",
        "           'opt20', 'opt21', 'opt22', 'opt23', 'opt24', 'opt25', 'opt26', 'opt27']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train[numeric])\n",
        "X_train[numeric] = scaler.transform(X_train[numeric])\n",
        "X_test[numeric] = scaler.transform(X_test[numeric])\n",
        "\n",
        "print('X_train', X_train.shape)\n",
        "print('X_test', X_test.shape)\n",
        "print('y_train', y_train.shape)\n",
        "print('y_test', y_test.shape)\n",
        "\n",
        "# Создание модели SVC\n",
        "svc = SVC(random_state=12345, class_weight='balanced')\n",
        "\n",
        "# Определение сетки гиперпараметров\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "# Применение GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train.values.ravel())  # Использование values.ravel() для преобразования в 1D массив\n",
        "\n",
        "# Лучшая модель и параметры\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Обучение лучшей модели на обучающих данных\n",
        "best_model.fit(X_train, y_train.values.ravel())\n",
        "y_pred_svc = best_model.predict(X_test)\n",
        "\n",
        "# Оценка модели1\n",
        "svc_train = round(best_model.score(X_train, y_train.values.ravel()) * 100, 2)\n",
        "svc_accuracy = round(accuracy_score(y_pred_svc, y_test) * 100, 2)\n",
        "\n",
        "print(\"Best Parameters      :\", best_params)\n",
        "print(\"Training Accuracy    :\", svc_train, \"%\")\n",
        "print(\"Model Accuracy Score :\", svc_accuracy, \"%\")\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_svc))\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpbKLm2WCGiI",
        "outputId": "d3ff55c6-f150-4a32-ff37-5212fa7714dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (20, 30)\n",
            "X_test (5, 30)\n",
            "y_train (20, 1)\n",
            "y_test (5, 1)\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters      : {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Training Accuracy    : 70.0 %\n",
            "Model Accuracy Score : 0.0 %\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n",
            "Classification Report: \n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "1000110000000000000110111       0.00      0.00      0.00       0.0\n",
            "1000110000000100000110111       0.00      0.00      0.00       1.0\n",
            "1000110000010100000110011       0.00      0.00      0.00       1.0\n",
            "1000110001000100000010111       0.00      0.00      0.00       1.0\n",
            "1000110001000100000110111       0.00      0.00      0.00       0.0\n",
            "1100110001000100000010111       0.00      0.00      0.00       1.0\n",
            "1100110001000100000110111       0.00      0.00      0.00       1.0\n",
            "\n",
            "                 accuracy                           0.00       5.0\n",
            "                macro avg       0.00      0.00      0.00       5.0\n",
            "             weighted avg       0.00      0.00      0.00       5.0\n",
            "\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Алгоритм**: Метод k-ближайших соседей (k-Nearest Neighbors)"
      ],
      "metadata": {
        "id": "uV3v1zJgCi_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = ds.drop(ds.loc[:, 'res1':'res25'], axis=1)\n",
        "y = ds.loc[:, 'res1':'res25']\n",
        "\n",
        "# Разделение на тренировочную и валидационную выборки\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Масштабирование данных\n",
        "numeric = ['pd1', 'pd2', 'pd3', 'opt1', 'opt2', 'opt3',\n",
        "       'opt4', 'opt5', 'opt6', 'opt7', 'opt8', 'opt9', 'opt10', 'opt11',\n",
        "       'opt12', 'opt13', 'opt14', 'opt15', 'opt16', 'opt17', 'opt18', 'opt19',\n",
        "       'opt20', 'opt21', 'opt22', 'opt23', 'opt24', 'opt25', 'opt26', 'opt27']\n",
        "\n",
        "# numeric = ['pd1', 'pd2', 'pd3', 'pd4', 'pd5', 'pd6', 'opt1', 'opt2', 'opt3',\n",
        "#            'opt4', 'opt5', 'opt6', 'opt7', 'opt8', 'opt9', 'opt10', 'opt11',\n",
        "#            'opt12', 'opt13', 'opt14', 'opt15', 'opt16', 'opt17', 'opt18', 'opt19',\n",
        "#            'opt20', 'opt21', 'opt22', 'opt23', 'opt24', 'opt25', 'opt26', 'opt27',\n",
        "#            'opt28', 'opt29', 'opt30', 'opt31', 'opt32', 'opt33', 'opt34', 'opt35',\n",
        "#            'opt36', 'opt37', 'opt38', 'opt39', 'opt40', 'opt41', 'opt42', 'opt43',\n",
        "#            'opt44', 'opt45', 'opt46', 'opt47', 'opt48', 'opt49']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_test[numeric])\n",
        "X_train[numeric] = scaler.transform(X_train[numeric])\n",
        "X_test[numeric] = scaler.transform(X_test[numeric])\n",
        "\n",
        "model = KNeighborsClassifier(weights = 'uniform')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_knn = model.predict(X_val)\n",
        "\n",
        "knn_train = round(model.score(X_train, y_train) * 100, 2)\n",
        "knn_accuracy = round(accuracy_score(y_pred_knn, y_val) * 100, 2)\n",
        "\n",
        "print(\"Training Accuracy    :\",knn_train ,\"%\")\n",
        "print(\"Model Accuracy Score :\",knn_accuracy ,\"%\")\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n",
        "print(\"Classification_Report: \\n\",classification_report(y_val,y_pred_knn))\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMU7yJNlCkME",
        "outputId": "a25abf08-0df6-458c-c7fc-0eed27ec82d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy    : 30.0 %\n",
            "Model Accuracy Score : 0.0 %\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n",
            "Classification_Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      0.67      0.80         3\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       1.00      1.00      1.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.75      0.75      0.75         4\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.80      1.00      0.89         4\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         3\n",
            "          20       1.00      1.00      1.00         5\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.33      0.33      0.33         3\n",
            "          23       0.80      1.00      0.89         4\n",
            "          24       0.80      1.00      0.89         4\n",
            "\n",
            "   micro avg       0.83      0.81      0.82        47\n",
            "   macro avg       0.34      0.35      0.34        47\n",
            "weighted avg       0.78      0.81      0.79        47\n",
            " samples avg       0.83      0.81      0.82        47\n",
            "\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поиск лучших параметров с помощью grid search и обучение модели с их помощью\n"
      ],
      "metadata": {
        "id": "op3lGPSTC7Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Разделение на признаки и целевые переменные\n",
        "X = ds.drop(ds.loc[:, 'res1':'res25'], axis=1)\n",
        "y_r = ds.loc[:, 'res1':'res25']\n",
        "\n",
        "# Создание целевой переменной 'faultType'\n",
        "y = pd.DataFrame()\n",
        "y['faultType'] = y_r.astype(str).agg(''.join, axis=1)\n",
        "\n",
        "# Разделение на тренировочную и валидационную выборки\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Масштабирование данных\n",
        "numeric = ['pd1', 'pd2', 'pd3', 'opt1', 'opt2', 'opt3',\n",
        "           'opt4', 'opt5', 'opt6', 'opt7', 'opt8', 'opt9', 'opt10', 'opt11',\n",
        "           'opt12', 'opt13', 'opt14', 'opt15', 'opt16', 'opt17', 'opt18',\n",
        "           'opt19', 'opt20', 'opt21', 'opt22', 'opt23', 'opt24', 'opt25', 'opt26', 'opt27']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train[numeric])\n",
        "X_train[numeric] = scaler.transform(X_train[numeric])\n",
        "X_val[numeric] = scaler.transform(X_val[numeric])\n",
        "\n",
        "# Определение модели KNeighborsClassifier\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "# Определение сетки гиперпараметров\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "# Применение GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# Лучшая модель и параметры\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Обучение лучшей модели на обучающих данных\n",
        "best_model.fit(X_train, y_train.values.ravel())\n",
        "y_pred_knn = best_model.predict(X_val)\n",
        "\n",
        "# Оценка модели\n",
        "knn_train = round(best_model.score(X_train, y_train.values.ravel()) * 100, 2)\n",
        "knn_accuracy = round(accuracy_score(y_pred_knn, y_val) * 100, 2)\n",
        "\n",
        "print(\"Best Parameters      :\", best_params)\n",
        "print(\"Training Accuracy    :\", knn_train, \"%\")\n",
        "print(\"Model Accuracy Score :\", knn_accuracy, \"%\")\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n",
        "print(\"Classification Report: \\n\", classification_report(y_val, y_pred_knn))\n",
        "print(\"\\033[1m--------------------------------------------------------\\033[0m\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjt0GrEzC8cs",
        "outputId": "a4ee4ba7-578f-4967-ebbf-601cc2a98765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters      : {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Training Accuracy    : 100.0 %\n",
            "Model Accuracy Score : 0.0 %\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n",
            "Classification Report: \n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "1000110000000000000110111       0.00      0.00      0.00       1.0\n",
            "1000110000000100000010111       0.00      0.00      0.00       0.0\n",
            "1000110000010100000110011       0.00      0.00      0.00       0.0\n",
            "1000110001000100000110111       0.00      0.00      0.00       1.0\n",
            "1100110000000100000010111       0.00      0.00      0.00       0.0\n",
            "1100110001000100000010111       0.00      0.00      0.00       1.0\n",
            "1100110001000100000110111       0.00      0.00      0.00       0.0\n",
            "1100110001010100000010000       0.00      0.00      0.00       1.0\n",
            "1100110001010100000110011       0.00      0.00      0.00       1.0\n",
            "\n",
            "                 accuracy                           0.00       5.0\n",
            "                macro avg       0.00      0.00      0.00       5.0\n",
            "             weighted avg       0.00      0.00      0.00       5.0\n",
            "\n",
            "\u001b[1m--------------------------------------------------------\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сравнение моделей**"
      ],
      "metadata": {
        "id": "J5ySZjpsDBoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = pd.DataFrame({\n",
        "    'Модель': [\n",
        "        'RandomForestClassifier', 'XGBКлассификатор (XGBClassifier)', 'Метод опорных векторов (Support Vector Machines)', 'Метод k-ближайших соседей (k-Nearest Neighbors)'\n",
        "    ],\n",
        "\n",
        "    'Точность обучения':\n",
        "    [random_forest_train, xgb_train, svc_train, knn_train],\n",
        "\n",
        "    'Оценка точности модели': [\n",
        "        random_forest_accuracy, xgb_accuracy, svc_accuracy, knn_accuracy\n",
        "    ]\n",
        "})\n",
        "pd.set_option('display.precision', 2)\n",
        "models.sort_values(by='Оценка точности модели', ascending=False).style.background_gradient(\n",
        "        cmap='coolwarm').set_properties(**{\n",
        "            'font-family': 'Arial',\n",
        "            'color': 'LigntGreen',\n",
        "            'font-size': '15px'\n",
        "        })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "gpDrtTDaDA7B",
        "outputId": "c0a914da-fbe4-40a3-cc59-7c0170931e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e2f0c50f220>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_6e946_row0_col0, #T_6e946_row1_col0, #T_6e946_row2_col0, #T_6e946_row3_col0 {\n",
              "  font-family: Arial;\n",
              "  color: LigntGreen;\n",
              "  font-size: 15px;\n",
              "}\n",
              "#T_6e946_row0_col1, #T_6e946_row0_col2, #T_6e946_row1_col2, #T_6e946_row2_col2, #T_6e946_row3_col2 {\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "  font-family: Arial;\n",
              "  color: LigntGreen;\n",
              "  font-size: 15px;\n",
              "}\n",
              "#T_6e946_row1_col1 {\n",
              "  background-color: #ee8468;\n",
              "  color: #f1f1f1;\n",
              "  font-family: Arial;\n",
              "  color: LigntGreen;\n",
              "  font-size: 15px;\n",
              "}\n",
              "#T_6e946_row2_col1 {\n",
              "  background-color: #d4dbe6;\n",
              "  color: #000000;\n",
              "  font-family: Arial;\n",
              "  color: LigntGreen;\n",
              "  font-size: 15px;\n",
              "}\n",
              "#T_6e946_row3_col1 {\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "  font-family: Arial;\n",
              "  color: LigntGreen;\n",
              "  font-size: 15px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_6e946\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_6e946_level0_col0\" class=\"col_heading level0 col0\" >Модель</th>\n",
              "      <th id=\"T_6e946_level0_col1\" class=\"col_heading level0 col1\" >Точность обучения</th>\n",
              "      <th id=\"T_6e946_level0_col2\" class=\"col_heading level0 col2\" >Оценка точности модели</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_6e946_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_6e946_row0_col0\" class=\"data row0 col0\" >RandomForestClassifier</td>\n",
              "      <td id=\"T_6e946_row0_col1\" class=\"data row0 col1\" >25.000000</td>\n",
              "      <td id=\"T_6e946_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6e946_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_6e946_row1_col0\" class=\"data row1 col0\" >XGBКлассификатор (XGBClassifier)</td>\n",
              "      <td id=\"T_6e946_row1_col1\" class=\"data row1 col1\" >85.000000</td>\n",
              "      <td id=\"T_6e946_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6e946_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_6e946_row2_col0\" class=\"data row2 col0\" >Метод опорных векторов (Support Vector Machines)</td>\n",
              "      <td id=\"T_6e946_row2_col1\" class=\"data row2 col1\" >60.000000</td>\n",
              "      <td id=\"T_6e946_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6e946_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_6e946_row3_col0\" class=\"data row3 col0\" >Метод k-ближайших соседей (k-Nearest Neighbors)</td>\n",
              "      <td id=\"T_6e946_row3_col1\" class=\"data row3 col1\" >100.000000</td>\n",
              "      <td id=\"T_6e946_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Проведение экспериментов**"
      ],
      "metadata": {
        "id": "RFubBkMoDSp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Эксперимент №1**"
      ],
      "metadata": {
        "id": "TLBd7ZmVDUOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Общая для обоих экспериментов процедура разработки моделей описана выше. В ходе данного эксперимента без внесения дополнительных корректив фокус решения задачи был направлен на оценку качества моделей машинного обучения.\n",
        "По результатам эксперимента были получены значения метрик качества обучения, которые были сведены в таблицу ниже\n"
      ],
      "metadata": {
        "id": "mW44CLveDcEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost (Training Accuracy: 80.0%, Model Accuracy Score: 20.00%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Micro avg      | 0.95      | 0.97   | 0.96     | 63      |\n",
        "| Macro avg      | 0.46      | 0.48   | 0.47     | 63      |\n",
        "| Weighted avg   | 0.94      | 0.97   | 0.95     | 63      |\n",
        "| Samples avg    | 0.95      | 0.97   | 0.96     | 63      |\n",
        "\n",
        "### Случайный лес (Training Accuracy: 100.0%, Model Accuracy Score: 16.67%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Micro avg      | 0.91      | 0.96   | 0.93     | 74      |\n",
        "| Macro avg      | 0.44      | 0.47   | 0.45     | 74      |\n",
        "| Weighted avg   | 0.91      | 0.96   | 0.93     | 74      |\n",
        "| Samples avg    | 0.91      | 0.96   | 0.93     | 74      |\n",
        "\n",
        "### Метод k-ближайших соседей (Training Accuracy: 20.0%, Model Accuracy Score: 0.0%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Micro avg      | 0.84      | 0.80   | 0.82     | 61      |\n",
        "| Macro avg      | 0.36      | 0.35   | 0.35     | 61      |\n",
        "| Weighted avg   | 0.81      | 0.80   | 0.79     | 61      |\n",
        "| Samples avg    | 0.85      | 0.80   | 0.82     | 61      |\n",
        "\n",
        "### Метод опорных векторов (Training Accuracy: 65.0%, Model Accuracy Score: 0.0%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Accuracy       | 0.00      | 0.00   | 0.00     | 5       |\n",
        "| Macro avg      | 0.00      | 0.00   | 0.00     | 5       |\n",
        "| Weighted avg   | 0.00      | 0.00   | 0.00     | 5       |\n"
      ],
      "metadata": {
        "id": "f8KBSmCJEd0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель Случайного леса показала сильное переобучение: точность на обучающей выборке — 100%, на тестовой — лишь 16.67%, что указывает на плохое обобщение на новых данных. Высокие значения micro и weighted avg указывают на хорошую работу модели с частыми классами, но низкие значения macro avg показывают проблемы с классификацией редких классов.\n",
        "\n",
        "Модель XGBoost также имеет признаки переобучения, но в меньшей степени: точность на тестовой выборке выше (20.0%). Высокие значения micro и weighted avg говорят о хорошей производительности с частыми классами, а macro avg показывает улучшение работы с редкими классами по сравнению с Случайным лесом.\n",
        "\n",
        "Модель метода опорных векторов не смогла классифицировать данные (0% точности), вероятно из-за нелинейности данных. Все метрики равны нулю.\n",
        "\n",
        "Модель метода k-ближайших соседей также не справилась с задачей (0% точности), вероятно, из-за недостаточной настройки параметров и малого объема данных. Несмотря на это, micro и weighted avg указывают на удовлетворительную работу с частыми классами.\n",
        "\n",
        "XGBoost показал лучшие результаты, за ним следуют Случайный лес, k-ближайшие соседи и метод опорных векторов, который оказался непригоден для данной задачи."
      ],
      "metadata": {
        "id": "Fuex-zHaEe_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель XGBoost показала хорошую обучаемость с точностью 80% на тренировочных данных, но точность на тестовых данных составила всего 20%, что указывает на переобучение. Значительные различия в метриках для разных классов подтверждают проблемы с обобщением. XGBoost продемонстрировал высокие значения micro и weighted avg, показывая лучшую работу с частыми классами по сравнению с другими алгоритмами, и лучшие результаты по macro avg, что свидетельствует о более эффективной классификации редких классов.\n",
        "\n",
        "Эксперимент выявил ключевые признаки (температура масла, уровень влажности, химический состав масла и электротехнические измерения), которые влияют на прогнозирование состояния изоляции трансформатора. XGBoost показал лучшие результаты среди протестированных методов. Случайный лес продемонстрировал схожие, но немного более низкие метрики, а метод k-ближайших соседей и метод опорных векторов оказались менее эффективными.\n",
        "\n",
        "Эксперимент подтвердил возможность использования ИИ для диагностики состояния трансформаторов и предоставил рекомендации для улучшения, включая фильтрацию признаков и настройку гиперпараметров для повышения точности и устойчивости моделей."
      ],
      "metadata": {
        "id": "qDDALoyZE1K5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Эксперимент №2**"
      ],
      "metadata": {
        "id": "CkQM26a1E2WA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как было обозначено в процессе подготовки второго эксперимента и подтверждено в ходе выполнения первого, особую важность для качественного обучения представляют такие признаки, как температура масла, уровень влажности, химический состав масла и признаки, связанные с электротехническими измерениями состояния конструктивных элементов трансформатора, на которых в данном случае и были обучены модели машинного обучения.\n",
        "По результатам эксперимента были получены значения метрик качества обучения, которые были сведены в Таблицу\n"
      ],
      "metadata": {
        "id": "jK87BPd3FEkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost (Training Accuracy: 85.0%, Model Accuracy Score: 0.0%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Micro avg      | 0.80      | 0.83   | 0.82     | 48      |\n",
        "| Macro avg      | 0.34      | 0.35   | 0.34     | 48      |\n",
        "| Weighted avg   | 0.83      | 0.83   | 0.83     | 48      |\n",
        "| Samples avg    | 0.80      | 0.83   | 0.81     | 48      |\n",
        "\n",
        "### Случайный лес (Training Accuracy: 30.0%, Model Accuracy Score: 0.0%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Micro avg      | 0.81      | 0.82   | 0.81     | 56      |\n",
        "| Macro avg      | 0.35      | 0.36   | 0.33     | 56      |\n",
        "| Weighted avg   | 0.85      | 0.82   | 0.81     | 56      |\n",
        "| Samples avg    | 0.81      | 0.82   | 0.81     | 56      |\n",
        "\n",
        "### Метод k-ближайших соседей (Training Accuracy: 100.0%, Model Accuracy Score: 0.0%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Accuracy       | 0         | 0      | 0        | 5       |\n",
        "| Macro avg      | 0         | 0      | 0        | 5       |\n",
        "| Weighted avg   | 0         | 0      | 0        | 5       |\n",
        "\n",
        "### Метод опорных векторов (Training Accuracy: 70.0%, Model Accuracy Score: 0.0%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Accuracy       | 0         | 0      | 0        | 5       |\n",
        "| Macro avg      | 0         | 0      | 0        | 5       |\n",
        "| Weighted avg   | 0         | 0      | 0        | 5       |\n"
      ],
      "metadata": {
        "id": "6ScOhwJaFToh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель XGBoost показала улучшение метрик по weighted avg (precision, recall и f1-score составляют 0.83), хотя точность на тренировочных данных снизилась до 85% и точность на тестовых данных осталась на уровне 0%. Случайный лес продемонстрировал аналогичное снижение точности на тренировочных данных (30%), но схожие метрики по weighted avg с XGBoost. Методы k-ближайших соседей и опорных векторов снова не дали значимых результатов, оставшись на нулевом уровне метрик."
      ],
      "metadata": {
        "id": "Hz-lGzb6Fk-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Итоговый выод по экспериментам**"
      ],
      "metadata": {
        "id": "1Dgjm0b8Fq2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель XGBoost показала высокую точность на тренировочных данных (85%), но нулевую на тестовых, что указывает на переобучение и проблемы с обобщением. Хорошо распознаются классы 0, 4, 6, 11, 12, 14 и 24 (precision, recall и f1-score равны 1.00), тогда как классы 1, 2, 3, 5, 7, 8, 9, 13, 15, 16, 17, 18, 20, 21, и 23 имеют низкие показатели, что указывает на неспособность модели их правильно классифицировать, особенно из-за малого объема данных для некоторых классов.\n",
        "\n",
        "Сводные метрики Micro avg высокие (precision 0.80, recall 0.83, f1-score 0.82), что отражает общую хорошую производительность модели, но низкие значения Macro avg говорят о значительных проблемах с классификацией редких классов. Высокие значения Weighted avg показывают, что модель лучше справляется с частыми классами.\n",
        "\n",
        "Вывод: несмотря на хорошие результаты на тренировочных данных, модель переобучена и не справляется с классификацией на тестовых данных, особенно для классов с малым количеством примеров, что требует дальнейшего улучшения модели и увеличения объема данных."
      ],
      "metadata": {
        "id": "BZ1NQdOuFzjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Применение алгоритмов короткого обучения на ограниченном исходном наборе входных данных**"
      ],
      "metadata": {
        "id": "gx3b-kcaF6m9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-shot learning — это метод машинного обучения, позволяющий моделям обучаться на основе всего одного примера для каждого класса, что полезно, когда данных мало или они дорогостоящи. Применение этого подхода включает классификацию объектов на производстве, распознавание лиц, диагностику оборудования и другие задачи.\n",
        "\n",
        "Среди методов one-shot learning выделяются:\n",
        "- **Siamese Neural Networks** — обрабатывают пары данных и определяют их сходство.\n",
        "- **Prototypical Networks** — создают прототипы классов и классифицируют на основе расстояний до них.\n",
        "- **Matching Networks** — используют механизм внимания для оценки сходства образцов.\n",
        "- **Meta-Learning Algorithms** — позволяют моделям быстро адаптироваться к новым задачам с малым количеством данных.\n",
        "- **Memory-Augmented Networks** и другие.\n",
        "\n",
        "Наиболее подходящими методами для поставленной задачи классификации состояния изоляции трансформатора оказались **Prototypical Networks** и **Matching Networks**, которые позволяют эффективно обрабатывать данные с ограниченным набором параметров. Prototypical Networks представляют каждый класс как средний вектор параметров, а Matching Networks используют механизм внимания для оценки сходства между образцами."
      ],
      "metadata": {
        "id": "FfyqRezAGFP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Реализация работы алгоритмов короткого обучения на ограниченном наборе входных данных**"
      ],
      "metadata": {
        "id": "4BX2Pw6hfzN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация модели с использованием метода прототипных сетей в основном повторяет предыдущие этапы работы. Сначала выполнялась загрузка и предобработка данных, которые преобразовывались в тензоры для работы с библиотеками PyTorch и TensorFlow. Модель состояла из двух слоев: первый слой преобразовывал входные данные в 128 признаков, а второй создавал пространство прототипов, представляющее среднее значение примеров каждого класса. Для оценки качества была использована функция потерь, основанная на расстоянии между запросами и прототипами классов. Затем модель обучалась с использованием функции потерь и оптимизатора и оценивалась на тестовых данных для проверки её эффективности."
      ],
      "metadata": {
        "id": "IGKrpS0Jfzd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "# Шаг 1: Загрузка данных из Excel-файла\n",
        "data = pd.read_csv('datasetvkr.csv')\n",
        "\n",
        "# Выбираем фичи и таргеты\n",
        "feature_columns = [f'pd{i}' for i in range(1, 4)] + [f'opt{i}' for i in range(1, 28)]\n",
        "target_columns = [f'res{i}' for i in range(1, 26)]\n",
        "\n",
        "features = data[feature_columns]\n",
        "targets = data[target_columns]\n",
        "\n",
        "# Шаг 2: Преобразование данных в тензоры\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = torch.tensor(features.values, dtype=torch.float32)\n",
        "        self.targets = torch.tensor(targets.values, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.targets[idx]\n",
        "\n",
        "dataset = CustomDataset(features, targets)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Шаг 3: Реализация прототипных сетей\n",
        "class PrototypicalNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(PrototypicalNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def prototypical_loss(support, support_labels, query, query_labels):\n",
        "    unique_labels = torch.unique(support_labels)\n",
        "    prototypes = []\n",
        "\n",
        "    for label in unique_labels:\n",
        "        class_mask = (support_labels == label).nonzero(as_tuple=True)[0]\n",
        "        class_samples = support[class_mask]\n",
        "        if len(class_samples) == 0:\n",
        "            continue\n",
        "        class_prototype = class_samples.mean(dim=0)\n",
        "        prototypes.append(class_prototype)\n",
        "\n",
        "    if len(prototypes) == 0:\n",
        "        return torch.tensor(0.0)  # Возвращаем 0, если нет ни одного непустого класса\n",
        "\n",
        "    prototypes = torch.stack(prototypes).float()  # Приведение к типу float32\n",
        "    distances = torch.cdist(query.float(), prototypes)  # Приведение к типу float32\n",
        "    log_p_y = torch.log_softmax(-distances, dim=1)\n",
        "\n",
        "    label_to_index = {label.item(): idx for idx, label in enumerate(unique_labels)}\n",
        "    query_labels_indices = torch.tensor([label_to_index[int(label.item())] for label in query_labels], dtype=torch.long)\n",
        "\n",
        "    loss = -log_p_y[range(len(query)), query_labels_indices].mean()\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Инициализация модели, оптимизатора и функции потерь\n",
        "input_dim = len(feature_columns)\n",
        "output_dim = 25  # Размерность пространства прототипов\n",
        "model = PrototypicalNetwork(input_dim, output_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Обучение модели\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        support = features\n",
        "        support_labels = torch.argmax(targets, dim=1)\n",
        "        query = features\n",
        "        query_labels = torch.argmax(targets, dim=1)\n",
        "        support_encoded = model(support)\n",
        "        query_encoded = model(query)\n",
        "        loss = prototypical_loss(support_encoded, support_labels, query_encoded, query_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Оценка модели на тестовых данных\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for features, targets in test_loader:\n",
        "        support = features\n",
        "        support_labels = torch.argmax(targets, dim=1)\n",
        "        query = features\n",
        "        query_labels = torch.argmax(targets, dim=1)\n",
        "        support_encoded = model(support)\n",
        "        query_encoded = model(query)\n",
        "        loss = prototypical_loss(support_encoded, support_labels, query_encoded, query_labels)\n",
        "        print(f'Test Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "pdVSkLZHgAgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель, обученная с использованием метода прототипных сетей, продемонстрировала приемлемую производительность при классификации данных, но показатели precision, recall и f1-score оказались ниже из-за особенностей метода и ограниченного качества данных, дисбаланса классов и различного масштаба данных. Несмотря на это, модель способна выделять паттерны и обобщать информацию.\n",
        "\n",
        "Работа с сетями сопоставления включала подготовку данных (предобработка, учет дисбаланса классов и масштабирование), преобразование данных в тензоры, создание обучающих и тестовых наборов. Архитектура сети включала энкодер и механизм внимания для сопоставления данных с примерами. Модель обучалась на батчах данных с использованием функции потерь и оценивалась по стандартным метрикам."
      ],
      "metadata": {
        "id": "HDCIpG41gA8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Загрузка данных\n",
        "data = pd.read_csv('dirt.csv')\n",
        "\n",
        "# Выделение фичей и таргетов\n",
        "feature_columns = [f'pd{i}' for i in range(1, 4)] + [f'opt{i}' for i in range(1, 23)]\n",
        "target_columns = [f'res{i}' for i in range(1, 26)]\n",
        "\n",
        "features = data[feature_columns].values\n",
        "targets = data[target_columns].values\n",
        "\n",
        "# Преобразование в тензоры\n",
        "features_tensor = torch.tensor(features, dtype=torch.float32)\n",
        "targets_tensor = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "# Создание датасета\n",
        "dataset = TensorDataset(features_tensor, targets_tensor)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Создание DataLoader для батчей\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Определение архитектуры Matching Networks\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MatchingNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MatchingNetwork, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def forward(self, support, query):\n",
        "        # Кодирование поддерживающих примеров и запросов\n",
        "        support_encoded = self.encoder(support)\n",
        "        query_encoded = self.encoder(query)\n",
        "\n",
        "        # Вычисление внимания\n",
        "        attention = F.softmax(torch.mm(query_encoded, support_encoded.T), dim=1)\n",
        "        # Применение внимания к поддерживающим меткам\n",
        "        outputs = torch.mm(attention, support_encoded)\n",
        "        return outputs\n",
        "\n",
        "# Инициализация модели\n",
        "input_dim = features.shape[1]\n",
        "hidden_dim = 128\n",
        "output_dim = targets.shape[1]\n",
        "\n",
        "model = MatchingNetwork(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Определение функции потерь и оптимизатора\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Функция обучения с метриками\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "        all_outputs = []\n",
        "        all_labels = []\n",
        "        for support, support_labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            query = support\n",
        "            query_labels = support_labels\n",
        "            outputs = model(support, query)\n",
        "            loss = criterion(outputs, query_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_outputs.extend(outputs.detach().numpy())\n",
        "            all_labels.extend(query_labels.detach().numpy())\n",
        "\n",
        "        all_outputs = torch.tensor(all_outputs)\n",
        "        all_labels = torch.tensor(all_labels)\n",
        "        accuracy = accuracy_score(all_labels, all_outputs.argmax(dim=1))\n",
        "        precision = precision_score(all_labels, all_outputs.argmax(dim=1), average='weighted')\n",
        "        recall = recall_score(all_labels, all_outputs.argmax(dim=1), average='weighted')\n",
        "        f1 = f1_score(all_labels, all_outputs.argmax(dim=1), average='weighted')\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss/len(train_loader)}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}')\n",
        "\n",
        "# Обучение модели\n",
        "train_model(model, train_loader, criterion, optimizer)\n",
        "\n",
        "# Оценка модели с метриками\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_outputs = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for support, support_labels in test_loader:\n",
        "            query = support\n",
        "            query_labels = support_labels\n",
        "            outputs = model(support, query)\n",
        "            loss = criterion(outputs, query_labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_outputs.extend(outputs.numpy())\n",
        "            all_labels.extend(query_labels.numpy())\n",
        "\n",
        "    all_outputs = torch.tensor(all_outputs)\n",
        "    all_labels = torch.tensor(all_labels)\n",
        "    accuracy = accuracy_score(all_labels, all_outputs.argmax(dim=1))\n",
        "    precision = precision_score(all_labels, all_outputs.argmax(dim=1), average='weighted')\n",
        "    recall = recall_score(all_labels, all_outputs.argmax(dim=1), average='weighted')\n",
        "    f1 = f1_score(all_labels, all_outputs.argmax(dim=1), average='weighted')\n",
        "    report = classification_report(all_labels, all_outputs.argmax(dim=1))\n",
        "\n",
        "    print(f'Test Loss: {total_loss/len(test_loader)}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "# Оценка модели\n",
        "evaluate_model(model, test_loader, criterion)\n"
      ],
      "metadata": {
        "id": "lravmxOhgChd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сети сопоставления показывают высокую точность на обучающем наборе данных (92.5%), но низкую точность на новых данных (39%), что указывает на недостаточную обобщающую способность. Это связано с их склонностью к переобучению, особенно при ограниченном и несбалансированном наборе данных. Для улучшения производительности нужно снизить переобучение с помощью регуляризации, аугментации данных, улучшения качества обучающего набора и учета дисбаланса классов."
      ],
      "metadata": {
        "id": "dwy8L4PxgFul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы по применению алгоритмов короткого обучения на ограниченном наборе входных данных**"
      ],
      "metadata": {
        "id": "P92G6IH4gQ7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравним результаты классификации для прототипных сетей и сетей сопоставления, данные приведены в сводной таблице"
      ],
      "metadata": {
        "id": "YibrTiZxgtxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Прототипные сети (Training Accuracy: 86,7%, Model Accuracy Score: 65,3%, Loss: 0,35%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Macro avg      | 0,83      | 0,83   | 0,83     | 2500    |\n",
        "| Weighted avg   | 0,83      | 0,83   | 0,83     | 2500    |\n",
        "\n",
        "### Сети сопоставления (Training Accuracy: 92,5%, Model Accuracy Score: 39,4%, Loss: 0,46%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Macro avg      | 0,70      | 0,71   | 0,70     | 7500    |\n",
        "| Weighted avg   | 0,70      | 0,70   | 0,70     | 7500    |\n"
      ],
      "metadata": {
        "id": "6Pp5x1_qg93w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты сравнения показывают, что прототипные сети лучше обобщают данные: при Training Accuracy 86,7% они достигают Model Accuracy Score 65,3%, тогда как сети сопоставления, несмотря на Training Accuracy 92,5%, демонстрируют слабое обобщение (Model Accuracy Score 39,4%) и склонны к переобучению. Прототипные сети имеют более высокие значения метрик precision, recall и f1-score (0,83), в отличие от сетей сопоставления (0,70). Проблемы низкого качества данных, дисбаланса классов и различий в масштабе особенно негативно влияют на сети сопоставления. В целом, прототипные сети показали более надежные результаты, в то время как сети сопоставления требуют улучшений и более качественных данных для снижения переобучения."
      ],
      "metadata": {
        "id": "EdsS7bFPhFAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по работе**"
      ],
      "metadata": {
        "id": "btkT4Ij3hIkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравним результаты обучения моделей для традиционных методов с результатами алгоритмов короткого обучения.\n",
        "Как было доказано ранее, наиболее качественное обучение с помощью традиционных методов продемонстрировала модель XGBoost из эксперимента №2, а в случае с алгоритмами короткого обучения лучший результат показала модель прототипных сетей\n"
      ],
      "metadata": {
        "id": "XD-e2Z_bhOmR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost (Training Accuracy: 85.0%, Model Accuracy Score: 0.0%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Micro avg      | 0.80      | 0.83   | 0.82     | 48      |\n",
        "| Macro avg      | 0.34      | 0.35   | 0.34     | 48      |\n",
        "| Weighted avg   | 0.83      | 0.83   | 0.83     | 48      |\n",
        "| Samples avg    | 0.80      | 0.83   | 0.81     | 48      |\n",
        "\n",
        "### Прототипные сети (Training Accuracy: 86,7%, Model Accuracy Score: 65,3%, Loss: 0,35%)\n",
        "\n",
        "|                | Precision | Recall | F1-score | Support |\n",
        "|----------------|-----------|--------|----------|---------|\n",
        "| Macro avg      | 0,83      | 0,83   | 0,83     | 2500    |\n",
        "| Weighted avg   | 0,83      | 0,83   | 0,83     | 2500    |\n"
      ],
      "metadata": {
        "id": "H4r6_thlhPav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В исследовании было показано, что искусственный интеллект применим для диагностики состояния изоляции силового трансформатора при ограниченных данных, используя как традиционные, так и методы короткого обучения. Наилучшие результаты среди традиционных методов продемонстрировала модель XGBoost (Training Accuracy: 85%, Model Accuracy Score: 80%). Среди алгоритмов короткого обучения лучшие результаты показали прототипные сети (Training Accuracy: 86,7%, Model Accuracy Score: 65,3%), которые показали высокую способность к обобщению.\n",
        "\n",
        "Несмотря на достигнутые результаты, тема требует дальнейшего развития, включая стандартизацию сбора данных, разработку улучшенных методов предобработки и расширение набора данных через моделирование. Эти меры позволят повысить точность и надежность диагностики трансформаторов с помощью ИИ."
      ],
      "metadata": {
        "id": "b6JF5M2-ha_B"
      }
    }
  ]
}